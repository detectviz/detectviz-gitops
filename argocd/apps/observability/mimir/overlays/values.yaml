# Mimir Configuration (Production with S3 Backend)
# 本文件為 Grafana Mimir 在生產環境的 Helm Chart Values，使用 Minio S3 作為後端儲存。
#
# 參考文件:
# - 本平台指南: gitops-argocd/guide/mimir.md
# - Helm Chart 官方文檔: https://github.com/grafana/helm-charts/tree/main/charts/mimir-distributed

# 禁用內建的 MinIO，使用獨立部署的 Minio 實例。
minio:
  enabled: false

# --- Mimir 核心配置 ---
mimir:
  structuredConfig:
    # 禁用認證，由 NetworkPolicy 和 Gateway 進行訪問控制。
    # 來自內部 Prometheus 的 remote-write 流量被視為可信。
    auth_enabled: false

    # **[關鍵]** 使用 S3 (Minio) 作為後端儲存，實現可擴展的長期 TSDB 儲存。
    # 參考: guide/mimir.md#1.3-儲存
    blocks_storage:
      backend: s3
      s3:
        endpoint: minio.monitoring.svc.cluster.local:9000
        bucket_name: mimir-blocks
        access_key_id: mimir
        secret_access_key: ${MINIO_SECRET_KEY}
        insecure: true  # 內部通訊使用 HTTP，生產環境可考慮啟用 TLS

    # **[關鍵]** 使用 memberlist (gossip 協議) 進行服務發現，這是 HA 的基礎。
    # 參考: guide/mimir.md#1.2-高可用性
    memberlist:
      join_members:
        - mimir-gossip-ring.monitoring.svc.cluster.local

    # **[關鍵]** Alertmanager 配置也使用 S3 儲存
    alertmanager_storage:
      backend: s3
      s3:
        endpoint: minio.monitoring.svc.cluster.local:9000
        bucket_name: mimir-alertmanager
        access_key_id: mimir
        secret_access_key: ${MINIO_SECRET_KEY}
        insecure: true

    # **[關鍵]** Ruler 配置使用 S3 儲存
    ruler_storage:
      backend: s3
      s3:
        endpoint: minio.monitoring.svc.cluster.local:9000
        bucket_name: mimir-ruler
        access_key_id: mimir
        secret_access_key: ${MINIO_SECRET_KEY}
        insecure: true

# --- 元件配置 (Component Configuration) ---
# **[關鍵]** 將所有關鍵元件的副本數設為 2，以實現高可用。
# 參考: guide/mimir.md#1.2-高可用性

# Alertmanager (Mimir 內建，用於多租戶告警)
alertmanager:
  replicas: 2
  # **[修正]** 使用 S3 backend，Alertmanager 配置儲存在 S3，不需要 PVC
  persistentVolume:
    enabled: false
  resources:
    requests:
      cpu: 100m
      memory: 256Mi
    limits:
      cpu: 500m
      memory: 512Mi
  nodeSelector: &appWorkerNodeSelector
    node-role.kubernetes.io/workload-apps: "true"
  tolerations: &controlPlaneTolerations
    - key: "node-role.kubernetes.io/control-plane"
      operator: "Exists"
      effect: "NoSchedule"
    - key: "node-role.kubernetes.io/master"
      operator: "Exists"
      effect: "NoSchedule"

# Ingester (負責接收與寫入指標數據)
ingester:
  replicas: 2
  # **[修正]** 使用 S3 backend，WAL 寫入 S3，不需要本地 PVC
  persistentVolume:
    enabled: false
  resources:
    requests:
      cpu: 200m
      memory: 512Mi
    limits:
      cpu: 1000m
      memory: 2Gi
  nodeSelector: *appWorkerNodeSelector
  tolerations: *controlPlaneTolerations

# Store Gateway (負責從長期儲存中讀取舊數據)
store_gateway:
  replicas: 2
  # **[修正]** 使用 S3 backend，直接從 S3 讀取 blocks，不需要 PVC
  persistentVolume:
    enabled: false
  resources:
    requests:
      cpu: 100m
      memory: 256Mi
    limits:
      cpu: 500m
      memory: 1Gi
  nodeSelector: *appWorkerNodeSelector
  tolerations: *controlPlaneTolerations

# Compactor (負責壓縮與合併 TSDB blocks，優化儲存與查詢)
compactor:
  replicas: 2
  # **[修正]** 使用 S3 backend，直接操作 S3 中的 blocks，不需要 PVC
  persistentVolume:
    enabled: false
  resources:
    requests:
      cpu: 100m
      memory: 256Mi
    limits:
      cpu: 500m
      memory: 1Gi
  nodeSelector: *appWorkerNodeSelector
  tolerations: *controlPlaneTolerations

# Distributor (接收 Prometheus remote-write 流量的入口)
distributor:
  replicas: 2
  resources:
    requests:
      cpu: 100m
      memory: 256Mi
    limits:
      cpu: 500m
      memory: 512Mi
  nodeSelector: *appWorkerNodeSelector
  tolerations: *controlPlaneTolerations

# Querier (執行 PromQL 查詢)
querier:
  replicas: 2
  resources:
    requests:
      cpu: 100m
      memory: 256Mi
    limits:
      cpu: 500m
      memory: 1Gi
  nodeSelector: *appWorkerNodeSelector
  tolerations: *controlPlaneTolerations

# Query Frontend (查詢隊列與快取)
query_frontend:
  replicas: 2
  resources:
    requests:
      cpu: 100m
      memory: 256Mi
    limits:
      cpu: 500m
      memory: 512Mi
  nodeSelector: *appWorkerNodeSelector
  tolerations: *controlPlaneTolerations

# --- 可觀測性 (Observability) ---
# **[關鍵]** 啟用 ServiceMonitor，讓 Prometheus 可以抓取 Mimir 自身的指標。
# 參考: guide/mimir.md#2.3-可觀測性
metaMonitoring:
  serviceMonitor:
    enabled: true
    namespace: monitoring
    labels:
      prometheus: kube-prometheus-stack # 確保被正確的 Prometheus 實例選中。
      environment: production
  # 啟用 Mimir 內建的告警規則。
  prometheusRule:
    enabled: true
    mimirRules: true
    mimirAlerts: true

# --- 環境變數 (注入 Minio Secret Key) ---
# **[關鍵]** 從 Secret 中注入 Minio 的 Secret Key
global:
  extraEnv:
    - name: MINIO_SECRET_KEY
      valueFrom:
        secretKeyRef:
          name: minio-mimir-user
          key: secretKey
