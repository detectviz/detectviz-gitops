# DetectViz GitOps éƒ¨ç½²æŒ‡å—

**åŸºæ–¼æ¶æ§‹**: `README.md` (4 VM æ··åˆè² è¼‰æ¨¡å‹ + é›™ç¶²è·¯æ¶æ§‹)

æœ¬æ–‡ä»¶æä¾›å®Œæ•´çš„éƒ¨ç½²æµç¨‹ï¼Œå¾ Proxmox ç¶²è·¯é…ç½®åˆ° Kubernetes é›†ç¾¤å•Ÿå‹•çš„æ‰€æœ‰æ­¥é©Ÿã€‚

---

## éƒ¨ç½²æµç¨‹æ¦‚è¦½

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          å‰ç½®ä½œæ¥­ (ä¸€æ¬¡æ€§)                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1. Proxmox é›™ç¶²è·¯é…ç½® (vmbr0 + vmbr1)                               â”‚
â”‚ 2. DNS ä¼ºæœå™¨é…ç½® (dnsmasq)                                         â”‚
â”‚ 3. VM æ¨¡æ¿æº–å‚™ (Ubuntu 22.04)                                       â”‚
â”‚ 4. SSH é‡‘é‘°æº–å‚™                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Phase 1: Terraform åŸºç¤è¨­æ–½                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ å»ºç«‹ 4 å° VM (3 master + 1 worker)                                â”‚
â”‚ â€¢ é…ç½®é›™ç¶²è·¯ (192.168.0.0/24 + 10.0.0.0/24)                         â”‚
â”‚ â€¢ é…ç½®é›™ç£ç¢Ÿæ¶æ§‹ (worker: 100GB system + 250GB data)                â”‚
â”‚ â€¢ ç”Ÿæˆ Ansible inventory                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Phase 2: ç¶²è·¯é…ç½®é©—è­‰                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ é©—è­‰é›™ç¶²è·¯é€£é€šæ€§                                                   â”‚
â”‚ â€¢ é©—è­‰ DNS è§£æ (detectviz.internal + cluster.internal)             â”‚
â”‚ â€¢ é©—è­‰ MTU è¨­å®š                                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Phase 3: Ansible è‡ªå‹•åŒ–éƒ¨ç½²                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Phase 3.1: Common Role (ç³»çµ±åˆå§‹åŒ–)                                 â”‚
â”‚ Phase 3.2: Network Role (é›™ç¶²è·¯é…ç½®)                                â”‚
â”‚ Phase 3.3: Master Role (Kubernetes æ§åˆ¶å¹³é¢ + HA)                   â”‚
â”‚ Phase 3.4: Worker Role (åŠ å…¥é›†ç¾¤ + LVM è‡ªå‹•é…ç½®)                    â”‚
â”‚ Phase 3.5: Node Labels (å·¥ä½œè² è¼‰æ¨™ç±¤)                               â”‚
â”‚ Phase 3.6: ArgoCD éƒ¨ç½² + Git SSH èªè­‰è‡ªå‹•åŒ– ğŸ¤–                      â”‚
â”‚ Phase 3.7: æœ€çµ‚é©—è­‰                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 Phase 4: GitOps åŸºç¤è¨­æ–½åŒæ­¥                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 4.1: æª¢æŸ¥ ArgoCD ç‹€æ…‹                                                â”‚
â”‚ 4.2: ç²å– ArgoCD å¯†ç¢¼                                                â”‚
â”‚ 4.3: è¨ªå• ArgoCD UI                                                 â”‚
â”‚ 4.4: Git Repository SSH èªè­‰ (ğŸ¤– å·²è‡ªå‹•åŒ–)                         â”‚
â”‚ 4.5: ç†è§£ Bootstrap åˆ†éšæ®µéƒ¨ç½²                                      â”‚
â”‚      â”œâ”€ Phase 1: Namespaces (ç«‹å³éƒ¨ç½²) âœ…                           â”‚
â”‚      â””â”€ Phase 2: Certificates, Ingress (ç­‰å¾… CRDs) â³              â”‚
â”‚ 4.6: é©—è­‰ ApplicationSet åŒæ­¥                                       â”‚
â”‚ 4.7: æ‰‹å‹•åŒæ­¥åŸºç¤è¨­æ–½ Applications ğŸ‘‰ æ‚¨åœ¨é€™è£¡                      â”‚
â”‚      â”œâ”€ infra-cert-manager (æä¾› CRDs)                              â”‚
â”‚      â”œâ”€ infra-ingress-nginx                                          â”‚
â”‚      â”œâ”€ infra-metallb                                                â”‚
â”‚      â”œâ”€ infra-external-secrets-operator                              â”‚
â”‚      â”œâ”€ infra-vault                                                  â”‚
â”‚      â””â”€ infra-topolvm                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Phase 5: Vault åˆå§‹åŒ–                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ åˆå§‹åŒ– Vault (ç”Ÿæˆ Unseal Keys + Root Token)                      â”‚
â”‚ â€¢ è§£å°æ‰€æœ‰ Vault å¯¦ä¾‹ (vault-0, vault-1, vault-2)                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Phase 6: æ‡‰ç”¨éƒ¨ç½²                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ PostgreSQL (è³‡æ–™åº«)                                                â”‚
â”‚ â€¢ Prometheus (æŒ‡æ¨™æ”¶é›†)                                              â”‚
â”‚ â€¢ Loki (æ—¥èªŒèšåˆ)                                                    â”‚
â”‚ â€¢ Tempo (åˆ†æ•£å¼è¿½è¹¤)                                                 â”‚
â”‚ â€¢ Mimir (é•·æœŸæŒ‡æ¨™å„²å­˜)                                               â”‚
â”‚ â€¢ Grafana (å¯è¦–åŒ–)                                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Phase 7: æœ€çµ‚é©—è­‰                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ é›†ç¾¤å¥åº·æª¢æŸ¥ (Nodes, Pods, Events)                                â”‚
â”‚ â€¢ ç¶²è·¯é©—è­‰ (é›™ç¶²è·¯, MetalLB, Ingress)                               â”‚
â”‚ â€¢ DNS é©—è­‰ (å…§å¤–éƒ¨åŸŸåè§£æ)                                          â”‚
â”‚ â€¢ æœå‹™ UI è¨ªå• (ArgoCD, Grafana, Prometheus, etc.)                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**é—œéµæç¤º**:
- ğŸ¤– = å·²è‡ªå‹•åŒ–,ç„¡éœ€æ‰‹å‹•æ“ä½œ
- â³ = éœ€è¦ç­‰å¾…å‰ç½®æ­¥é©Ÿå®Œæˆ
- ğŸ‘‰ = ç•¶å‰éœ€è¦åŸ·è¡Œçš„æ­¥é©Ÿ

---

## å·²è§£æ±ºçš„"é›ç”Ÿè›‹"ä¾è³´å•é¡Œ

æœ¬éƒ¨ç½²æµç¨‹å·²å®Œæ•´è§£æ±ºä»¥ä¸‹å¾ªç’°ä¾è³´å•é¡Œï¼ˆè©³è¦‹[æ•…éšœæ’é™¤](#æ•…éšœæ’é™¤)ç« ç¯€ï¼‰ï¼š

### å•é¡Œ #1: ApplicationSet è·¯å¾‘é…ç½®
- **ç—‡ç‹€**: ArgoCD ç„¡æ³•æ‰¾åˆ°æ‡‰ç”¨è·¯å¾‘
- **è§£æ±ºæ–¹æ¡ˆ**: âœ… æ‰€æœ‰ ApplicationSet è·¯å¾‘å·²åŒ…å« `argocd/` å‰ç¶´
- **é©—è­‰**: `argocd/appsets/appset.yaml` å·²ä¿®æ­£

### å•é¡Œ #2: AppProject æ¬Šé™ç™½åå–®
- **ç—‡ç‹€**: åŸºç¤è¨­æ–½æ‡‰ç”¨ç„¡æ³•å‰µå»º Namespace æˆ– IngressClass
- **è§£æ±ºæ–¹æ¡ˆ**: âœ… `platform-bootstrap` é …ç›®å·²åŒ…å«æ‰€æœ‰å¿…è¦è³‡æºæ¬Šé™
- **é©—è­‰**: `argocd/bootstrap/argocd-projects.yaml` å·²é…ç½®å®Œæ•´

### å•é¡Œ #3: CRD ä¾è³´é †åº
- **ç—‡ç‹€**: cluster-bootstrap å˜—è©¦å‰µå»º Certificate ä½† cert-manager CRD å°šæœªå®‰è£
- **è§£æ±ºæ–¹æ¡ˆ**: âœ… ä½¿ç”¨ Sync Wave åˆ†éšæ®µéƒ¨ç½² + `SkipDryRunOnMissingResource=true`
- **é æœŸè¡Œç‚º**: cluster-bootstrap Phase 2 æœƒå…ˆå¤±æ•—ï¼Œå¾…åŸºç¤è¨­æ–½åŒæ­¥å¾Œè‡ªå‹•é‡è©¦æˆåŠŸ
- **é©—è­‰**: åŸºç¤è¨­æ–½åŒæ­¥å¾Œ cluster-bootstrap è‡ªå‹•è®Šç‚º Synced

### å•é¡Œ #4: TopoLVM èª¿åº¦æ¨¡å¼
- **ç—‡ç‹€**: Vault pods é¡¯ç¤º "Insufficient capacity" ä½†å¯¦éš›æœ‰è¶³å¤ ç©ºé–“
- **æ ¹æœ¬åŸå› **: Scheduler Extender æ¨¡å¼æœªå®Œæ•´é…ç½®
- **è§£æ±ºæ–¹æ¡ˆ**: âœ… æ”¹ç”¨ Storage Capacity Tracking æ¨¡å¼ï¼ˆKubernetes 1.21+ åŸç”Ÿï¼‰
- **é©—è­‰**: `argocd/apps/infrastructure/topolvm/overlays/values.yaml` å·²å•Ÿç”¨ `storageCapacityTracking`

### å•é¡Œ #5: Vault Pod Anti-Affinity èˆ‡å–® Worker Node
- **ç—‡ç‹€**: vault-1/vault-2 pods æŒçºŒ Pendingï¼ŒéŒ¯èª¤ "didn't match pod anti-affinity rules"
- **æ ¹æœ¬åŸå› **: Vault Helm chart é»˜èªä½¿ç”¨ `requiredDuringSchedulingIgnoredDuringExecution` anti-affinityï¼Œè¦æ±‚æ¯å€‹ pod åœ¨ä¸åŒ node ä¸Šï¼Œä½†æ¸¬è©¦ç’°å¢ƒåªæœ‰ 1 å€‹ worker node
- **è§£æ±ºæ–¹æ¡ˆ**: âœ… æ”¹ç”¨ `preferredDuringSchedulingIgnoredDuringExecution` (weight: 100)
  - å…è¨±å¤šå€‹ Vault pods åœ¨åŒä¸€ node ä¸Šé‹è¡Œï¼ˆæ¸¬è©¦ç’°å¢ƒï¼‰
  - ç•¶æœ‰å¤šå€‹ worker nodes æ™‚ä»æœƒå˜—è©¦åˆ†æ•£ï¼ˆç”Ÿç”¢ç’°å¢ƒï¼‰
- **é©—è­‰**: `argocd/apps/infrastructure/vault/overlays/values.yaml` å·²æ·»åŠ  `server.affinity` é…ç½®
- **ç”Ÿç”¢å»ºè­°**: å¤š worker node ç’°å¢ƒå¯è€ƒæ…®æ”¹å› `required` ä»¥æé«˜å¯ç”¨æ€§

### å•é¡Œ #6: ArgoCD Server URL é…ç½®æœªç”Ÿæ•ˆ
- **ç—‡ç‹€**: ArgoCD UI ç„¡æ³•æ­£ç¢ºé¡¯ç¤º `https://argocd.detectviz.internal` URL,å½±éŸ¿ SSO å›èª¿å’Œç‹€æ…‹å¾½ç« 
- **æ ¹æœ¬åŸå› **: ArgoCD ç”± Ansible é€šé Helm chart å®‰è£,`argocd-cm.yaml` é…ç½®å¾æœªè¢«æ‡‰ç”¨åˆ°å¯¦éš›é‹è¡Œçš„ ConfigMap
- **è§£æ±ºæ–¹æ¡ˆ**: âœ… å•Ÿç”¨ ArgoCD è‡ªæˆ‘ç®¡ç†é…ç½®
  - æ·»åŠ  ArgoCD åˆ° ApplicationSet (`argocd/appsets/appset.yaml`)
  - å‰µå»º config-only ç®¡ç†æ¨¡å¼ï¼ˆä¸é‡æ–°éƒ¨ç½² ArgoCD æœ¬èº«ï¼‰
  - åªç®¡ç†é…ç½®æ–‡ä»¶ (`argocd-cm.yaml`)ï¼Œé¿å…èˆ‡ Ansible å®‰è£è¡çª
- **è‡¨æ™‚ä¿®å¾©**: å·²æ‰‹å‹• patch ConfigMap: `kubectl patch configmap argocd-cm -n argocd --type merge -p '{"data":{"url":"https://argocd.detectviz.internal"}}'`
- **é©—è­‰**: `argocd/apps/infrastructure/argocd/overlays/kustomization.yaml` å·²æ”¹ç‚º config-only æ¨¡å¼
- **å½±éŸ¿**: æœªä¾†é…ç½®è®Šæ›´å¯é€šé GitOps ç®¡ç†,ç„¡éœ€æ‰‹å‹•æ“ä½œ

### å•é¡Œ #7: Ingress-Nginx LoadBalancer ç„¡æ³•åˆ†é… IP
- **ç—‡ç‹€**: ingress-nginx-controller æœå‹™ EXTERNAL-IP ç‚º `<pending>`ï¼Œç„¡æ³•è¨ªå• https://argocd.detectviz.internal
- **æ ¹æœ¬åŸå› **:
  1. MetalLB IP æ± é…ç½®ä¸å®Œæ•´ï¼ˆç¼ºå°‘ 192.168.0.10ï¼‰
  2. ä½¿ç”¨ deprecated `spec.loadBalancerIP` æ¬„ä½èˆ‡è¨»è§£è¡çª
  3. `externalTrafficPolicy: Local` å°è‡´å¥åº·æª¢æŸ¥å¤±æ•—ï¼ŒIP è¢«æ’¤å›
- **è§£æ±ºæ–¹æ¡ˆ**: âœ… å®Œæ•´ä¿®å¾©é…ç½®
  - æ·»åŠ  `192.168.0.10/32` åˆ° MetalLB IPAddressPool
  - ç§»é™¤ deprecated `spec.loadBalancerIP` æ¬„ä½
  - ä½¿ç”¨ `externalTrafficPolicy: Cluster` æ¨¡å¼
  - é€šé strategic merge patch æ­£ç¢ºé…ç½®æœå‹™
- **é©—è­‰**: EXTERNAL-IP æˆåŠŸåˆ†é…ç‚º 192.168.0.10ï¼ŒHTTPS æ­£å¸¸è¨ªå•
- **ç›¸é—œæ–‡ä»¶**: `ingress-nginx-loadbalancer-fix.md`
- **Commits**: bbab4f2, 16bb52d, 8bafac7, 959332d

**éƒ¨ç½²å»ºè­°**:
- âš ï¸ **cluster-bootstrap é¡¯ç¤º OutOfSync æ˜¯æ­£å¸¸çš„**ï¼Œåœ¨åŸºç¤è¨­æ–½åŒæ­¥å‰æœƒæŒçºŒæ­¤ç‹€æ…‹
- âœ… **æ‰€æœ‰é…ç½®æ–‡ä»¶å·²ä¿®æ­£**ï¼Œç„¡éœ€æ‰‹å‹•èª¿æ•´
- ğŸ“‹ **éµå¾ªæœ¬æ–‡ä»¶æ­¥é©Ÿ**ï¼Œå•é¡Œæœƒè‡ªå‹•è§£æ±º

---

## ç›®éŒ„

- [å‰ç½®ä½œæ¥­](#å‰ç½®ä½œæ¥­)
  - [1. Proxmox é›™ç¶²è·¯é…ç½®](#1-proxmox-é›™ç¶²è·¯é…ç½®)
  - [2. DNS ä¼ºæœå™¨é…ç½®](#2-dns-ä¼ºæœå™¨é…ç½®)
  - [3. VM æ¨¡æ¿æº–å‚™](#3-vm-æ¨¡æ¿æº–å‚™)
  - [4. SSH é‡‘é‘°æº–å‚™](#4-ssh-é‡‘é‘°æº–å‚™)
- [éƒ¨ç½²æµç¨‹](#éƒ¨ç½²æµç¨‹)
  - [Phase 1: Terraform åŸºç¤è¨­æ–½ä½ˆå»º](#phase-1-terraform-åŸºç¤è¨­æ–½ä½ˆå»º)
  - [Phase 2: ç¶²è·¯é…ç½®é©—è­‰](#phase-2-ç¶²è·¯é…ç½®é©—è­‰)
  - [Phase 3: Ansible è‡ªå‹•åŒ–éƒ¨ç½²](#phase-3-ansible-è‡ªå‹•åŒ–éƒ¨ç½²)
  - [Phase 4: GitOps åŸºç¤è¨­æ–½åŒæ­¥](#phase-4-gitops-åŸºç¤è¨­æ–½åŒæ­¥)
  - [Phase 5: Vault åˆå§‹åŒ–](#phase-5-vault-åˆå§‹åŒ–)
  - [Phase 6: æ‡‰ç”¨éƒ¨ç½²](#phase-6-æ‡‰ç”¨éƒ¨ç½²)
  - [Phase 7: æœ€çµ‚é©—è­‰](#phase-7-æœ€çµ‚é©—è­‰)
- [æ•…éšœæ’é™¤](#æ•…éšœæ’é™¤)

---

## å‰ç½®ä½œæ¥­

### 1. Proxmox é›™ç¶²è·¯é…ç½®

DetectViz ä½¿ç”¨é›™ç¶²è·¯æ¶æ§‹ä»¥åˆ†é›¢ç®¡ç†æµé‡èˆ‡é›†ç¾¤å…§éƒ¨é€šè¨Šã€‚

**åƒè€ƒæ–‡ä»¶**: `docs/infrastructure/00-planning/configuration-network.md`

#### 1.1 é…ç½®ç¶²è·¯æ©‹æ¥å™¨

ç·¨è¼¯ `/etc/network/interfaces`ï¼š

```bash
# å‚™ä»½ç¾æœ‰é…ç½®
cp /etc/network/interfaces /etc/network/interfaces.backup

# ç·¨è¼¯ç¶²è·¯é…ç½®
vi /etc/network/interfaces
```

**é…ç½®å…§å®¹**ï¼š

```bash
# å¤–éƒ¨ç¶²è·¯æ©‹æ¥å™¨ (vmbr0 - enp4s0)
auto vmbr0
iface vmbr0 inet static
    address 192.168.0.2/24
    gateway 192.168.0.1
    bridge-ports enp4s0
    bridge-stp off
    bridge-fd 0
    mtu 1500

# å…§éƒ¨é›†ç¾¤ç¶²è·¯æ©‹æ¥å™¨ (vmbr1 - enp5s0)
auto vmbr1
iface vmbr1 inet static
    address 10.0.0.2/24
    bridge-ports enp5s0
    bridge-stp off
    bridge-fd 0
    mtu 1500
```

> **MTU è¨­å®šèªªæ˜**:
> - **é è¨­ 1500**: é©ç”¨æ–¼æ‰€æœ‰æ¨™æº–ç¶²å¡å’Œäº¤æ›æ©Ÿï¼Œå»ºè­°ä½¿ç”¨
> - **é€²éš 9000**: éœ€è¦ç¶²å¡ã€äº¤æ›æ©Ÿã€ç·šæå…¨éƒ¨æ”¯æ´å·¨å‹å¹€ï¼ˆJumbo Framesï¼‰ï¼Œå¦å‰‡æœƒå°è‡´é€£ç·šå¤±æ•—
> - **è¨ºæ–·æ–¹æ³•**: å¦‚æœè¨­å®š 9000 å¾Œç„¡æ³•é€£ç·šï¼Œè«‹æ”¹å› 1500

#### 1.2 é…ç½® sysctl åƒæ•¸

```bash
cat <<EOF | tee /etc/sysctl.d/99-proxmox-network.conf
# Proxmox Host Network Configuration
net.ipv4.conf.all.rp_filter = 2
net.ipv4.conf.default.rp_filter = 2
net.bridge.bridge-nf-call-iptables = 1
net.ipv4.ip_forward = 1
net.ipv6.conf.all.disable_ipv6 = 1
EOF

sysctl --system
```

#### 1.3 é‡å•Ÿç¶²è·¯æœå‹™

```bash
systemctl restart networking
```

#### 1.4 é©—è­‰é…ç½®

```bash
# æª¢æŸ¥æ©‹æ¥å™¨ç‹€æ…‹
ip addr show vmbr0
ip addr show vmbr1

# é©—è­‰ MTU
ip link show vmbr0 | grep mtu
ip link show vmbr1 | grep mtu

# é©—è­‰ sysctl
sysctl net.ipv4.ip_forward
sysctl net.ipv4.conf.all.rp_filter
```

**é æœŸçµæœ**ï¼š
- vmbr0: 192.168.0.2/24, MTU 1500
- vmbr1: 10.0.0.2/24, MTU 1500
- ip_forward = 1
- rp_filter = 2

---

### 2. DNS ä¼ºæœå™¨é…ç½®

DetectViz ä½¿ç”¨ Proxmox dnsmasq æä¾›å…§éƒ¨ DNS è§£æã€‚

**åƒè€ƒæ–‡ä»¶**: `docs/infrastructure/00-planning/configuration-domain.md`

#### 2.1 å®‰è£ dnsmasq

```bash
apt update
apt install dnsmasq -y
```

#### 2.2 é…ç½® dnsmasq

å‰µå»º `/etc/dnsmasq.d/detectviz.conf`ï¼š

```bash
cat <<EOF | tee /etc/dnsmasq.d/detectviz.conf
# DetectViz DNS Configuration
domain=detectviz.internal
expand-hosts
local=/detectviz.internal/

# å¤–éƒ¨ç¶²è·¯è¨˜éŒ„ (vmbr0)
address=/proxmox.detectviz.internal/192.168.0.2
address=/ipmi.detectviz.internal/192.168.0.4
address=/k8s-api.detectviz.internal/192.168.0.10
address=/master-1.detectviz.internal/192.168.0.11
address=/master-2.detectviz.internal/192.168.0.12
address=/master-3.detectviz.internal/192.168.0.13
address=/app-worker.detectviz.internal/192.168.0.14

# å…§éƒ¨é›†ç¾¤ç¶²è·¯åŸŸå
local=/cluster.internal/

# å…§éƒ¨ç¶²è·¯è¨˜éŒ„ (vmbr1)
address=/master-1.cluster.internal/10.0.0.11
address=/master-2.cluster.internal/10.0.0.12
address=/master-3.cluster.internal/10.0.0.13
address=/app-worker.cluster.internal/10.0.0.14

# æ‡‰ç”¨æœå‹™
address=/argocd.detectviz.internal/192.168.0.10
address=/grafana.detectviz.internal/192.168.0.10
address=/prometheus.detectviz.internal/192.168.0.10
address=/loki.detectviz.internal/192.168.0.10
address=/tempo.detectviz.internal/192.168.0.10
address=/pgadmin.detectviz.internal/192.168.0.10

# ä¸Šæ¸¸ DNS
server=8.8.8.8
server=1.1.1.1

listen-address=127.0.0.1,192.168.0.2
bind-interfaces
EOF
```

#### 2.3 å•Ÿå‹• dnsmasq

```bash
systemctl enable --now dnsmasq
systemctl restart dnsmasq
systemctl status dnsmasq
```

#### 2.4 é©—è­‰ DNS

```bash
# æ¸¬è©¦å¤–éƒ¨åŸŸåè§£æ
dig @192.168.0.2 master-1.detectviz.internal +short
# é æœŸ: 192.168.0.11

# æ¸¬è©¦é›†ç¾¤å…§éƒ¨åŸŸåè§£æ
dig @192.168.0.2 master-1.cluster.internal +short
# é æœŸ: 10.0.0.11

# æ¸¬è©¦å¤–éƒ¨ DNS è½‰ç™¼
dig @192.168.0.2 google.com +short
# é æœŸ: Google IP ä½å€
```

---

### 3. VM æ¨¡æ¿æº–å‚™

**åƒè€ƒæ–‡ä»¶**: `docs/infrastructure/02-proxmox/vm-template-creation.md`

ç¢ºä¿å·²å»ºç«‹ Ubuntu 22.04 Cloud-init æ¨¡æ¿ï¼ˆVM ID: 9000ï¼‰

é©—è­‰æ¨¡æ¿ï¼š

```bash
pvesh get /nodes/proxmox/qemu --output-format json | jq -r '.[] | select(.template==1) | .name'
# é æœŸè¼¸å‡º: ubuntu-2204-template
```

---

### 4. SSH é‡‘é‘°æº–å‚™

```bash
# æª¢æŸ¥æ˜¯å¦å·²æœ‰ SSH é‡‘é‘°
ls -la ~/.ssh/id_rsa.pub

# å¦‚æœæ²’æœ‰ï¼Œç”Ÿæˆæ–°çš„é‡‘é‘°å°
ssh-keygen -t rsa -b 4096 -C "your_email@example.com"
```

---

## éƒ¨ç½²æµç¨‹

### Phase 1: Terraform åŸºç¤è¨­æ–½ä½ˆå»º

**ç›®æ¨™**: å»ºç«‹ 4 å° VMï¼Œé…ç½®é›™ç¶²è·¯æ¶æ§‹ï¼ˆvmbr0 + vmbr1ï¼‰

#### 1.1 æª¢æŸ¥ Terraform é…ç½®

ç¢ºèª `terraform/terraform.tfvars` é…ç½®æ­£ç¢ºï¼š

```bash
cd terraform/

# æª¢æŸ¥ç¶²è·¯é…ç½®
grep -E 'proxmox_bridge|k8s_overlay_bridge|master_internal_ips|worker_internal_ips|cluster_domain' terraform.tfvars

# æª¢æŸ¥ç£ç¢Ÿé…ç½®
grep -E 'worker_system_disk_sizes|worker_data_disks' terraform.tfvars
```

**é æœŸè¼¸å‡º - ç¶²è·¯é…ç½®**ï¼š
```
proxmox_bridge     = "vmbr0"          # å¤–éƒ¨ç¶²è·¯ (ç®¡ç† + æ‡‰ç”¨)
k8s_overlay_bridge = "vmbr1"          # å…§éƒ¨ç¶²è·¯ (Kubernetes ç¯€é»é–“é€šè¨Š)
master_internal_ips = ["10.0.0.11", "10.0.0.12", "10.0.0.13"]
worker_internal_ips = ["10.0.0.14"]
cluster_domain      = "cluster.internal"
```

**é æœŸè¼¸å‡º - ç£ç¢Ÿé…ç½®ï¼ˆé›™ç£ç¢Ÿæ¶æ§‹ï¼‰**ï¼š
```hcl
worker_system_disk_sizes = ["100G"]    # ç³»çµ±ç£ç¢Ÿ (OS + kubelet)
worker_data_disks = [
  {
    size    = "250G"                   # è³‡æ–™ç£ç¢Ÿ (TopoLVM topolvm-vg)
    storage = "nvme-vm"
  }
]
```

**èªªæ˜**ï¼š
- **Master ç¯€é»**: å–®ç£ç¢Ÿ 100GB (OS + etcd)
- **Worker ç¯€é»**: é›™ç£ç¢Ÿæ¶æ§‹
  - `/dev/sda` 100GB: ç³»çµ±ç£ç¢Ÿ
  - `/dev/sdb` 250GB: è³‡æ–™ç£ç¢Ÿ (ä¾› TopoLVM ç®¡ç†ï¼Œå‹•æ…‹ PV)

#### 1.2 åˆå§‹åŒ–ä¸¦éƒ¨ç½²

```bash
terraform init
terraform plan -var-file=terraform.tfvars
terraform apply -auto-approve
```

#### 1.3 é©—è­‰ VM å‰µå»º

```bash
# æª¢æŸ¥ VM ç‹€æ…‹
pvesh get /nodes/proxmox/qemu --output-format json | jq -r '.[] | select(.vmid >= 111 and .vmid <= 114) | {vmid, name, status}'

# æ¸¬è©¦ SSH é€£æ¥
ssh ubuntu@192.168.0.11 'hostname'
ssh ubuntu@192.168.0.14 'hostname'

# æª¢æŸ¥ app-worker ç£ç¢Ÿé…ç½®
ssh ubuntu@192.168.0.14 'lsblk'
```

**é æœŸè¼¸å‡º (app-worker ç£ç¢Ÿ)**ï¼š
```
NAME   MAJ:MIN RM  SIZE RO TYPE MOUNTPOINTS
sda      8:0    0  100G  0 disk
â”œâ”€sda1   8:1    0    1M  0 part
â”œâ”€sda2   8:2    0    2G  0 part /boot
â””â”€sda3   8:3    0   98G  0 part
  â””â”€ubuntu--vg-ubuntu--lv 253:0 0 98G  0 lvm  /
sdb      8:16   0  250G  0 disk     â† è³‡æ–™ç£ç¢Ÿ (æœªæ ¼å¼åŒ–)
```

#### 1.4 TopoLVM Volume Group é…ç½®

**é‡è¦**: LVM Volume Group çš„å»ºç«‹å·²ç¶“**è‡ªå‹•åŒ–**åœ¨ Ansible éƒ¨ç½²æµç¨‹ä¸­ (Phase 4: Worker Role),**ç„¡éœ€æ‰‹å‹•æ“ä½œ**ã€‚

Ansible æœƒåœ¨ Phase 4 è‡ªå‹•åŸ·è¡Œ:
1. æª¢æŸ¥ /dev/sdb ç£ç¢Ÿæ˜¯å¦å­˜åœ¨
2. å»ºç«‹ Physical Volume (`pvcreate /dev/sdb`)
3. å»ºç«‹ Volume Group (`vgcreate topolvm-vg /dev/sdb`)
4. é©—è­‰ LVM é…ç½®

é…ç½®æª”æ¡ˆä½ç½®: `ansible/group_vars/all.yml:51-60`

```yaml
configure_lvm: true  # å•Ÿç”¨ LVM è‡ªå‹•é…ç½®

lvm_volume_groups:
  - name: topolvm-vg   # Volume Group åç¨±
    devices:
      - /dev/sdb       # ä½¿ç”¨çš„ç‰©ç†è¨­å‚™ (250GB è³‡æ–™ç£ç¢Ÿ)
```

**éƒ¨ç½²å¾Œé©—è­‰** (åœ¨ Phase 4 å®Œæˆå¾Œ):
```bash
# SSH åˆ° app-worker æª¢æŸ¥ LVM é…ç½®
ssh ubuntu@192.168.0.14 'sudo vgs && sudo pvs'
```

**é æœŸè¼¸å‡º**ï¼š
```bash
# vgs
  VG          #PV #LV #SN Attr   VSize    VFree
  topolvm-vg    1   0   0 wz--n- <250.00g <250.00g  â† TopoLVM VG (è‡ªå‹•å»ºç«‹)
  ubuntu-vg     1   1   0 wz--n-  <98.00g       0   â† ç³»çµ± VG
```

> **èªªæ˜**:
> - Ansible Worker Role æœƒè‡ªå‹•æª¢æŸ¥ä¸¦å»ºç«‹ LVM é…ç½®
> - å¦‚æœ VG å·²å­˜åœ¨,æœƒè‡ªå‹•è·³é (ignore_errors: true)
> - å¯é€éè¨­å®š `configure_lvm: false` åœç”¨è‡ªå‹• LVM é…ç½®

#### 1.5 TopoLVM Storage Capacity æ¨¡å¼é…ç½®

**é‡è¦**: TopoLVM ä½¿ç”¨ **Storage Capacity Tracking** æ¨¡å¼ï¼ˆKubernetes 1.21+ åŸç”ŸåŠŸèƒ½ï¼‰ï¼Œè€ŒéèˆŠçš„ Scheduler Extender æ¨¡å¼ã€‚

**é…ç½®æª”æ¡ˆ**: `argocd/apps/infrastructure/topolvm/overlays/values.yaml`

```yaml
scheduler:
  enabled: false  # ç¦ç”¨ scheduler extender (ä¸éœ€è¦)

controller:
  storageCapacityTracking:
    enabled: true  # å•Ÿç”¨ CSI Storage Capacity Tracking

webhook:
  podMutatingWebhook:
    enabled: false  # Storage Capacity æ¨¡å¼ä¸éœ€è¦ pod webhook
```

**Storage Capacity Tracking å„ªå‹¢**:
- âœ… Kubernetes åŸç”ŸåŠŸèƒ½ï¼ˆ1.21+ GAï¼‰
- âœ… ç„¡éœ€é…ç½® kube-scheduler extender
- âœ… æ›´ç°¡å–®ã€æ›´å¯é çš„èª¿åº¦æ©Ÿåˆ¶
- âœ… è‡ªå‹•å®¹é‡è¿½è¹¤å’Œå ±å‘Š

**éƒ¨ç½²å¾Œé©—è­‰** (åœ¨ Phase 4.7 å®Œæˆå¾Œ):
```bash
# æª¢æŸ¥ CSIStorageCapacity è³‡æº
kubectl get csistoragecapacity -A

# æª¢æŸ¥ TopoLVM controller æ—¥èªŒ
kubectl logs -n kube-system -l app.kubernetes.io/component=controller --tail=50
```

**é æœŸè¼¸å‡º**ï¼š
```
NAMESPACE      NAME                    STORAGECLASS           CAPACITY
kube-system    topolvm-<node>-<hash>   topolvm-provisioner    257693843456
```

#### 1.6 æª¢æŸ¥ç”Ÿæˆçš„æ–‡ä»¶

```bash
# å›åˆ° terraform ç›®éŒ„
cd /path/to/detectviz-gitops/terraform

# Ansible inventory
cat ../ansible/inventory.ini

# /etc/hosts ç‰‡æ®µ
cat ../hosts-fragment.txt
```

---

### Phase 2: ç¶²è·¯é…ç½®é©—è­‰

**ç›®æ¨™**: é©—è­‰é›™ç¶²è·¯æ¶æ§‹é…ç½®æ­£ç¢º

#### 2.1 åŸ·è¡Œç¶²è·¯é©—è­‰è…³æœ¬

```bash
cd ../scripts/
./validate-dual-network.sh
```

#### 2.2 æ‰‹å‹•é©—è­‰ï¼ˆå¯é¸ï¼‰

```bash
# æª¢æŸ¥ VM ç¶²è·¯ä»‹é¢
ssh ubuntu@192.168.0.11 'ip addr show eth0'
ssh ubuntu@192.168.0.11 'ip addr show eth1'

# æª¢æŸ¥ MTU è¨­å®š
ssh ubuntu@192.168.0.11 'ip link show eth0 | grep mtu'
ssh ubuntu@192.168.0.11 'ip link show eth1 | grep mtu'

# æ¸¬è©¦å…§éƒ¨ç¶²è·¯é€£é€šæ€§
ssh ubuntu@192.168.0.11 'ping -c 3 10.0.0.14'

# æ¸¬è©¦ DNS è§£æ
ssh ubuntu@192.168.0.11 'getent hosts master-1.detectviz.internal'
ssh ubuntu@192.168.0.11 'getent hosts master-1.cluster.internal'
```

**é æœŸçµæœ**ï¼š
- âœ… æ¯å€‹ VM æœ‰å…©å€‹ç¶²è·¯ä»‹é¢ (eth0, eth1)
- âœ… MTU éƒ½è¨­å®šç‚º 1500 (æˆ–æ‚¨è‡ªè¨‚çš„å€¼)
- âœ… å…§éƒ¨ç¶²è·¯å¯äº’é€š
- âœ… DNS æ­£ç¢ºè§£æå…©å€‹åŸŸå

---

### Phase 3: Ansible è‡ªå‹•åŒ–éƒ¨ç½²

**ç›®æ¨™**: éƒ¨ç½² Kubernetes é›†ç¾¤èˆ‡æ‰€æœ‰åŸºç¤è¨­æ–½çµ„ä»¶

#### 3.1 æª¢æŸ¥ Ansible Inventory

```bash
cd ../ansible/
cat inventory.ini

# æ¸¬è©¦ Ansible é€£æ¥
ansible all -i inventory.ini -m ping
```

#### 3.2 åŸ·è¡Œå®Œæ•´éƒ¨ç½²

```bash
ansible-playbook -i inventory.ini deploy-cluster.yml
```

**éƒ¨ç½²éšæ®µ**ï¼š
1. **[Phase 1] Common Role**: ç³»çµ±åˆå§‹åŒ–ã€å¥—ä»¶å®‰è£ã€Kubernetes å…§æ ¸åƒæ•¸é…ç½®
   - å®‰è£åŸºç¤å¥—ä»¶: `apt-transport-https`, `ca-certificates`, `curl`, `gnupg`, `python3-pip`
   - **å®‰è£ Python Kubernetes å®¢æˆ¶ç«¯**: `kubernetes`, `pyyaml`, `jsonpatch` (ä¾› ansible kubernetes.core æ¨¡çµ„ä½¿ç”¨)
   - å®‰è£ containerd (2.1.5) å’Œ Kubernetes çµ„ä»¶ (1.32.0)
   - å®‰è£ yq (YAML è™•ç†å™¨) ä¾›å¾ŒçºŒ manifest ä¿®æ”¹ä½¿ç”¨
   - é…ç½® Kubernetes å¿…è¦å…§æ ¸åƒæ•¸ï¼š
     - `net.ipv4.ip_forward=1` - å•Ÿç”¨ IP è½‰ç™¼ï¼ˆPod ç¶²è·¯è·¯ç”±ï¼‰
     - `net.bridge.bridge-nf-call-iptables=1` - æ©‹æ¥æµé‡ç¶“ iptables è™•ç†
     - `net.bridge.bridge-nf-call-ip6tables=1` - IPv6 æ©‹æ¥æµé‡è™•ç†
     - è¼‰å…¥ `br_netfilter` å…§æ ¸æ¨¡çµ„ä¸¦æŒä¹…åŒ–

2. **[Phase 2] Network Role**:
   - é…ç½®é›™ç¶²è·¯ä»‹é¢ (eth0: 192.168.0.0/24 + eth1: 10.0.0.0/24)
   - è¨­å®š /etc/hosts (detectviz.internal + cluster.internal é›™åŸŸå)
   - é…ç½®ç¶²è·¯ sysctl åƒæ•¸ (rp_filter=2 æ”¯æ´éå°ç¨±è·¯ç”±)

3. **[Phase 3] Master Role**: åˆå§‹åŒ– Kubernetes æ§åˆ¶å¹³é¢
   - åˆå§‹åŒ–ç¬¬ä¸€å€‹ master ç¯€é» (kubeadm init)
   - éƒ¨ç½² Kube-VIP (æ§åˆ¶å¹³é¢ HA çš„è™›æ“¬ IP)
   - å®‰è£ Calico CNI ç¶²è·¯æ’ä»¶
   - å…¶ä»– master ç¯€é»åŠ å…¥æ§åˆ¶å¹³é¢ (kubeadm join --control-plane)
   - **è¨­å®š kubeconfig**: ç‚º root å’Œ ansible_user (ubuntu) å»ºç«‹ ~/.kube/config

4. **[Phase 3.5] ç”Ÿæˆ Worker åŠ å…¥å‘½ä»¤**:
   - åœ¨ master-1 ä¸Šç”Ÿæˆ kubeadm join token
   - å°‡ join å‘½ä»¤å‹•æ…‹å‚³éçµ¦æ‰€æœ‰ worker ç¯€é»

5. **[Phase 4] Worker Role**: åŠ å…¥å·¥ä½œç¯€é»
   - é…ç½® LVM Volume Groups (topolvm-vg) ä¾› TopoLVM ä½¿ç”¨
   - ä½¿ç”¨ Phase 3.5 ç”Ÿæˆçš„ join å‘½ä»¤åŠ å…¥é›†ç¾¤
   - ç­‰å¾… kubelet å¥åº·æª¢æŸ¥é€šé

6. **[Phase 5] ç¯€é»æ¨™ç±¤**: ç‚ºç¯€é»æ·»åŠ å·¥ä½œè² è¼‰æ¨™ç±¤
   - master-1: `workload-monitoring=true` (Grafana, Prometheus)
   - master-2: `workload-mimir=true` (Mimir é•·æœŸæŒ‡æ¨™å„²å­˜)
   - master-3: `workload-loki=true` (Loki æ—¥èªŒèšåˆ)
   - app-worker: `workload-apps=true` (ArgoCD, æ‡‰ç”¨ç¨‹å¼)
   - **æ³¨æ„**: ä½¿ç”¨ `--kubeconfig=/etc/kubernetes/admin.conf` æ˜ç¢ºæŒ‡å®šé…ç½®æª”æ¡ˆ

7. **[Phase 6] ArgoCD éƒ¨ç½²**: å®‰è£ GitOps å¼•æ“
   - **è¨­å®šç’°å¢ƒè®Šæ•¸**: `KUBECONFIG=/etc/kubernetes/admin.conf` (ä¾› kubernetes.core.k8s æ¨¡çµ„ä½¿ç”¨)
   - å»ºç«‹ argocd namespace
   - ä¸‹è¼‰ ArgoCD å®˜æ–¹ manifest
   - ä½¿ç”¨ yq ç‚º ArgoCD çµ„ä»¶æ·»åŠ  nodeSelector (ç¢ºä¿éƒ¨ç½²åˆ° app-worker)
   - æ‡‰ç”¨ ArgoCD manifest
   - éƒ¨ç½² Root Application (App of Apps æ¨¡å¼)

8. **[Phase 7] æœ€çµ‚é©—è­‰**: é›†ç¾¤å¥åº·æª¢æŸ¥
   - ç­‰å¾…æ‰€æœ‰ç¯€é»é€²å…¥ Ready ç‹€æ…‹
   - é¡¯ç¤ºé›†ç¾¤ç¯€é»è³‡è¨Šå’Œéƒ¨ç½²æ‘˜è¦

#### 3.3 éƒ¨ç½²å¾Œé©—è­‰

```bash
# è¨­å®š kubeconfig
export KUBECONFIG=$(pwd)/kubeconfig/admin.conf

# æª¢æŸ¥ç¯€é»ç‹€æ…‹
kubectl get nodes -o wide

# æª¢æŸ¥ç¯€é»æ¨™ç±¤
kubectl get nodes --show-labels
```

**é æœŸè¼¸å‡º**ï¼š
```
NAME         STATUS   ROLES           AGE   VERSION
master-1     Ready    control-plane   10m   v1.32.0
master-2     Ready    control-plane   9m    v1.32.0
master-3     Ready    control-plane   8m    v1.32.0
app-worker   Ready    <none>          7m    v1.32.0
```

---

### Phase 4: GitOps åŸºç¤è¨­æ–½åŒæ­¥

**ç›®æ¨™**: é€é ArgoCD è‡ªå‹•éƒ¨ç½²åŸºç¤è¨­æ–½çµ„ä»¶

#### 4.1 æª¢æŸ¥ ArgoCD ç‹€æ…‹

```bash
# ç­‰å¾… ArgoCD å°±ç·’
kubectl wait --for=condition=Ready pod -l app.kubernetes.io/name=argocd-server -n argocd --timeout=300s

# æª¢æŸ¥ ArgoCD Pods
kubectl get pods -n argocd
```

#### 4.2 ç²å– ArgoCD å¯†ç¢¼

```bash
# ç²å–åˆå§‹å¯†ç¢¼
kubectl -n argocd get secret argocd-initial-admin-secret -o jsonpath="{.data.password}" | base64 -d
echo ""
```

#### 4.3 è¨ªå• ArgoCD UI

```bash
# é¸é … 1: Port Forward
kubectl port-forward svc/argocd-server -n argocd 8080:443

# é¸é … 2: é€šé Ingress (éœ€è¦å…ˆé…ç½® DNS)
# https://argocd.detectviz.internal
```

ç™»å…¥è³‡è¨Šï¼š
- **URL**: `https://localhost:8080` æˆ– `https://argocd.detectviz.internal`
- **Username**: `admin`
- **Password**: (ä¸Šä¸€æ­¥é©Ÿç²å–çš„å¯†ç¢¼)

#### 4.4 é…ç½® Git Repository SSH èªè­‰

> **ğŸ¤– è‡ªå‹•åŒ–**: æ­¤æ­¥é©Ÿå·²åœ¨ **Ansible Phase 6** ä¸­è‡ªå‹•å®Œæˆã€‚
>
> **å‰ç½®æ¢ä»¶**: SSH ç§é‘°å­˜åœ¨æ–¼ `~/.ssh/id_ed25519_detectviz`
>
> å¦‚æœæ‚¨çš„ SSH é‡‘é‘°å·²æº–å‚™å¥½,Ansible æœƒè‡ªå‹•:
> - âœ… è¤‡è£½ SSH é‡‘é‘°åˆ° master-1
> - âœ… å»ºç«‹ ArgoCD repository secret
> - âœ… é…ç½® GitHub SSH known_hosts
> - âœ… é‡å•Ÿ repo-server ä¸¦åˆ·æ–° root application
>
> **ä»¥ä¸‹æ‰‹å‹•æ­¥é©Ÿåƒ…ä¾›åƒè€ƒå’Œæ•…éšœæ’é™¤ä½¿ç”¨**ã€‚

---

**æ‰‹å‹•é…ç½®æ­¥é©Ÿ** (å¦‚æœè‡ªå‹•åŒ–å¤±æ•—æˆ–éœ€è¦æ‰‹å‹•å¹²é ):

ç”±æ–¼ Root Application ä½¿ç”¨ SSH URL è¨ªå• GitHub ç§æœ‰ repository,éœ€è¦é…ç½® SSH é‡‘é‘°:

```bash
# 1. è¤‡è£½ SSH ç§é‘°åˆ° master-1
scp ~/.ssh/id_ed25519_detectviz ubuntu@192.168.0.11:/tmp/argocd-ssh-key

# 2. å»ºç«‹ ArgoCD repository secret
ssh ubuntu@192.168.0.11 "sudo kubectl --kubeconfig=/etc/kubernetes/admin.conf create secret generic detectviz-gitops-repo --from-file=sshPrivateKey=/tmp/argocd-ssh-key -n argocd"

# 3. æ·»åŠ æ¨™ç±¤è®“ ArgoCD è­˜åˆ¥ç‚º repository credential
ssh ubuntu@192.168.0.11 "sudo kubectl --kubeconfig=/etc/kubernetes/admin.conf label secret detectviz-gitops-repo argocd.argoproj.io/secret-type=repository -n argocd --overwrite"

# 4. é…ç½® repository URL
ssh ubuntu@192.168.0.11 "sudo kubectl --kubeconfig=/etc/kubernetes/admin.conf patch secret detectviz-gitops-repo -n argocd -p='{\"stringData\":{\"type\":\"git\",\"url\":\"git@github.com:detectviz/detectviz-gitops.git\"}}'"

# 5. æ·»åŠ  GitHub SSH known_hosts
ssh-keyscan github.com > /tmp/github-hostkey
scp /tmp/github-hostkey ubuntu@192.168.0.11:/tmp/
ssh ubuntu@192.168.0.11 "sudo kubectl --kubeconfig=/etc/kubernetes/admin.conf create secret generic argocd-ssh-known-hosts --from-file=ssh_known_hosts=/tmp/github-hostkey -n argocd"

# 6. é‡å•Ÿ ArgoCD repo-server è¼‰å…¥æ–°çš„èªè­‰
ssh ubuntu@192.168.0.11 "sudo kubectl --kubeconfig=/etc/kubernetes/admin.conf rollout restart deployment argocd-repo-server -n argocd"
ssh ubuntu@192.168.0.11 "sudo kubectl --kubeconfig=/etc/kubernetes/admin.conf rollout status deployment argocd-repo-server -n argocd --timeout=60s"

# 7. å¼·åˆ¶åˆ·æ–° root application
ssh ubuntu@192.168.0.11 "sudo kubectl --kubeconfig=/etc/kubernetes/admin.conf patch application root -n argocd -p='{\"metadata\":{\"annotations\":{\"argocd.argoproj.io/refresh\":\"hard\"}}}' --type=merge"

# 8. æ¸…ç†è‡¨æ™‚æª”æ¡ˆ
ssh ubuntu@192.168.0.11 "rm -f /tmp/argocd-ssh-key /tmp/github-hostkey"
```

**ç­‰å¾…ç´„ 10-30 ç§’å¾Œ,é©—è­‰ Root Application ç‹€æ…‹**:
```bash
# æª¢æŸ¥ root application
kubectl get application root -n argocd
# é æœŸè¼¸å‡º: SYNC STATUS = Synced

# æª¢æŸ¥ ApplicationSets
kubectl get applicationset -n argocd
# é æœŸçœ‹åˆ°: argocd-bootstrap, detectviz-gitops
```

#### 4.5 ç†è§£ Bootstrap åˆ†éšæ®µéƒ¨ç½²

> **ğŸ“š è©³ç´°æ–‡æª”**: `argocd/bootstrap/PHASE_DEPLOYMENT.md`

ArgoCD Bootstrap è³‡æºæ¡ç”¨**å…©éšæ®µéƒ¨ç½²ç­–ç•¥**ä¾†è§£æ±º CRD ä¾è³´å•é¡Œ:

**Phase 1: åŸºç¤è³‡æº** (Sync Wave: -10)
- âœ… ç«‹å³éƒ¨ç½²: Namespaces (cert-manager, ingress-nginx, vault, etc.)
- âœ… ä¸ä¾è³´ä»»ä½• CRDs
- âœ… ç¸½æ˜¯æˆåŠŸ

**Phase 2: é€²éšè³‡æº** (Sync Wave: 10)
- â³ å»¶å¾Œéƒ¨ç½²: Certificates, ClusterIssuers, Ingress, ArgoCDExtensions
- â³ ä¾è³´åŸºç¤è¨­æ–½ CRDs (cert-manager, ingress-nginx, argo-rollouts)
- â³ ä½¿ç”¨ `SkipDryRunOnMissingResource=true` é¿å…é æª¢æŸ¥å¤±æ•—

**é æœŸè¡Œç‚º**:
```
1. Root Application åŒæ­¥ â†’ Synced, Healthy âœ…
2. cluster-bootstrap Phase 1 éƒ¨ç½² â†’ Namespaces å»ºç«‹æˆåŠŸ âœ…
3. åŸºç¤è¨­æ–½ ApplicationSets ç”Ÿæˆ Applications (cert-manager, ingress-nginx, etc.) âœ…
4. cluster-bootstrap Phase 2 å˜—è©¦éƒ¨ç½² â†’ å¤±æ•— (CRDs å°šæœªå®‰è£) âš ï¸  é€™æ˜¯æ­£å¸¸çš„!
5. æ‰‹å‹•åŒæ­¥åŸºç¤è¨­æ–½ Applications â†’ CRDs å®‰è£ âœ…
6. cluster-bootstrap Phase 2 è‡ªå‹•é‡è©¦ â†’ æˆåŠŸ âœ…
```

**ç‚ºä»€éº¼ cluster-bootstrap æœƒé¡¯ç¤ºéŒ¯èª¤?**

åœ¨åŸºç¤è¨­æ–½åŒæ­¥ä¹‹å‰,æ‚¨æœƒçœ‹åˆ°é¡ä¼¼çš„éŒ¯èª¤è¨Šæ¯:
```
resource mapping not found for name: "argocd-server-tls"
no matches for kind "Certificate" in version "cert-manager.io/v1"
ensure CRDs are installed first
```

**é€™æ˜¯æ­£å¸¸ä¸”é æœŸçš„è¡Œç‚º**,å› ç‚º:
- Phase 2 è³‡æºéœ€è¦ cert-manager çš„ `Certificate` CRD
- cert-manager å°šæœªéƒ¨ç½²,CRD ä¸å­˜åœ¨
- ä¸€æ—¦åŸºç¤è¨­æ–½åŒæ­¥å®Œæˆ,cluster-bootstrap æœƒè‡ªå‹•é‡è©¦ä¸¦æˆåŠŸ

---

#### 4.6 é©—è­‰ ApplicationSet åŒæ­¥

```bash
# æª¢æŸ¥ Root Application ç‹€æ…‹
kubectl get application root -n argocd
# é æœŸ: Synced, Healthy

# æª¢æŸ¥ cluster-bootstrap ç‹€æ…‹
kubectl get application cluster-bootstrap -n argocd
# é æœŸ: OutOfSync, Missing (ç­‰å¾…åŸºç¤è¨­æ–½ CRDs) - é€™æ˜¯æ­£å¸¸çš„!

# æª¢æŸ¥ ApplicationSet
kubectl get applicationset -n argocd

# æª¢æŸ¥æ‰€æœ‰æ‡‰ç”¨ç‹€æ…‹
argocd app list

# æª¢æŸ¥åŸºç¤è¨­æ–½çµ„ä»¶ (éƒ¨ç½²å¾Œ)
kubectl get pods -n metallb-system
kubectl get pods -n cert-manager
kubectl get pods -n ingress-nginx
kubectl get pods -n external-secrets-system
kubectl get pods -n vault
kubectl get pods -n topolvm-system
```

#### 4.7 æ‰‹å‹•åŒæ­¥åŸºç¤è¨­æ–½ Applications

> **ğŸ“– å¿«é€Ÿåƒè€ƒ**: è©³ç´°æ­¥é©Ÿè«‹åƒè€ƒ `QUICK_START.md`

æ­¤æ™‚åŸºç¤è¨­æ–½ Applications å·²è‡ªå‹•ç”Ÿæˆ,ä½†è™•æ–¼ `Unknown` ç‹€æ…‹,éœ€è¦æ‰‹å‹•è§¸ç™¼åŒæ­¥:

**é¸é … 1: åœ¨ ArgoCD UI ä¸­æ‰‹å‹•åŒæ­¥** (æ¨è–¦)

1. è¨ªå• ArgoCD UI (https://localhost:8080)
2. é»æ“Šæ¯å€‹ `infra-*` Application
3. é»æ“Š "SYNC" æŒ‰éˆ•
4. ç­‰å¾…åŒæ­¥å®Œæˆ

**å»ºè­°åŒæ­¥é †åº**:
1. `infra-argocd` (ArgoCD è‡ªæˆ‘é…ç½® - æ‡‰ç”¨ URL è¨­å®š)
2. `infra-cert-manager` (å„ªå…ˆ - æä¾› Certificate CRDs)
3. `infra-ingress-nginx`
4. `infra-metallb`
5. `infra-external-secrets-operator`
6. `infra-vault`
7. `infra-topolvm`

**æ³¨æ„**: `infra-argocd` æ˜¯ ArgoCD çš„é…ç½®ç®¡ç†æ‡‰ç”¨,æœƒè‡ªå‹•å‡ºç¾åœ¨ ApplicationSet ä¸­ã€‚å®ƒä¸æœƒé‡æ–°éƒ¨ç½² ArgoCD æœ¬èº«,åªç®¡ç†é…ç½®æ–‡ä»¶ï¼ˆå¦‚ server URLï¼‰ã€‚

**é¸é … 2: ä½¿ç”¨å‘½ä»¤è¡ŒåŒæ­¥**

```bash
# SSH åˆ° master-1
ssh ubuntu@192.168.0.11

# åŒæ­¥æ‰€æœ‰åŸºç¤è¨­æ–½ Applications
for app in infra-argocd infra-cert-manager infra-ingress-nginx infra-metallb \
           infra-external-secrets-operator infra-vault infra-topolvm; do
  sudo kubectl --kubeconfig=/etc/kubernetes/admin.conf patch application $app -n argocd \
    -p='{"operation":{"initiatedBy":{"username":"admin"},"sync":{"prune":true}}}' \
    --type=merge
  echo "âœ… Triggered sync for $app"
  sleep 5
done
```

**é¸é … 3: ä½¿ç”¨ ArgoCD CLI**

```bash
# 1. Port forward (åœ¨å¦ä¸€å€‹çµ‚ç«¯)
kubectl --kubeconfig=/etc/kubernetes/admin.conf \
  port-forward svc/argocd-server -n argocd 8080:443 &

# 2. ç™»å…¥ (ä½¿ç”¨ Phase 4.2 ç²å–çš„å¯†ç¢¼)
argocd login localhost:8080 \
  --username admin \
  --password <your-argocd-password> \
  --insecure

# 3. åŒæ­¥æ‰€æœ‰åŸºç¤è¨­æ–½ Applications
argocd app sync infra-cert-manager
argocd app sync infra-ingress-nginx
argocd app sync infra-metallb
argocd app sync infra-external-secrets-operator
argocd app sync infra-vault
argocd app sync infra-topolvm

# 4. æª¢æŸ¥ç‹€æ…‹
argocd app list
```

**é©—è­‰åŒæ­¥å®Œæˆ**:
```bash
# ç­‰å¾…æ‰€æœ‰ Pods é‹è¡Œ
kubectl get pods -n cert-manager
kubectl get pods -n ingress-nginx
kubectl get pods -n metallb-system
kubectl get pods -n external-secrets-system
kubectl get pods -n vault
kubectl get pods -n topolvm-system

# ç¢ºèª CRDs å·²å®‰è£
kubectl get crd | grep cert-manager
# é æœŸè¼¸å‡º: certificates.cert-manager.io, clusterissuers.cert-manager.io, issuers.cert-manager.io

# æª¢æŸ¥ cluster-bootstrap ç‹€æ…‹ (æ‡‰è©²è‡ªå‹•é‡è©¦ä¸¦æˆåŠŸ)
kubectl get application cluster-bootstrap -n argocd
# é æœŸ: Synced, Healthy (Phase 2 è³‡æºå·²éƒ¨ç½²)

# é©—è­‰ TopoLVM CSIStorageCapacity è³‡æº
kubectl get csistoragecapacity -A
# é æœŸ: æ‡‰è©²çœ‹åˆ° topolvm-provisioner çš„å®¹é‡è³‡æº
```

**é æœŸçµæœ**ï¼š
- âœ… æ‰€æœ‰åŸºç¤è¨­æ–½ Applications: Synced, Healthy
- âœ… cluster-bootstrap: Synced, Healthy (Phase 2 è‡ªå‹•é‡è©¦æˆåŠŸ)
- âœ… MetalLB é‹è¡Œä¸­ (LoadBalancer æ”¯æ´)
- âœ… cert-manager é‹è¡Œä¸­ (TLS è­‰æ›¸ç®¡ç† + CRDs)
- âœ… NGINX Ingress é‹è¡Œä¸­ (Ingress æ§åˆ¶å™¨)
- âœ… External Secrets é‹è¡Œä¸­ (Secret ç®¡ç†)
- âœ… Vault é‹è¡Œä¸­ (å¯†é‘°ç®¡ç†,å¾…åˆå§‹åŒ–)
- âœ… TopoLVM é‹è¡Œä¸­ (å‹•æ…‹ PV æä¾›ï¼Œä½¿ç”¨ Storage Capacity Tracking)

**å¸¸è¦‹å•é¡Œè™•ç†**:

å¦‚æœåŸºç¤è¨­æ–½ Applications é¡¯ç¤º `OutOfSync` æˆ– `Unknown` ä½†ä¸è‡ªå‹•åŒæ­¥ï¼š

```bash
# 1. æª¢æŸ¥ ArgoCD repo-server æ—¥èªŒ
kubectl logs -n argocd -l app.kubernetes.io/name=argocd-repo-server --tail=50

# 2. å¦‚æœçœ‹åˆ°è·¯å¾‘éŒ¯èª¤ï¼Œç¢ºèª ApplicationSet é…ç½®æ­£ç¢º
kubectl get applicationset detectviz-gitops -n argocd -o yaml | grep path

# 3. æ‰‹å‹•è§¸ç™¼ root application åˆ·æ–°
kubectl patch application root -n argocd \
  -p='{"metadata":{"annotations":{"argocd.argoproj.io/refresh":"hard"}}}' \
  --type=merge

# 4. ç­‰å¾… 30 ç§’å¾Œæª¢æŸ¥ç‹€æ…‹
sleep 30 && kubectl get applications -n argocd
```

---

### Phase 5: Vault åˆå§‹åŒ–

**ç›®æ¨™**: æ‰‹å‹•åˆå§‹åŒ–ä¸¦è§£å° Hashicorp Vault

#### 5.1 ç­‰å¾… Vault Pod å°±ç·’

```bash
kubectl get pods -n vault --watch
# ç­‰å¾…æ‰€æœ‰ vault-0/1/2 éƒ½è™•æ–¼ Running ç‹€æ…‹ (0/1 Ready æ˜¯æ­£å¸¸çš„,å› ç‚ºå°šæœª unseal)
# Ctrl+C é€€å‡º watch
```

**æ³¨æ„**:
- æ‰€æœ‰ 3 å€‹ Vault pods éƒ½æœƒé€²å…¥ Running ç‹€æ…‹ï¼Œä½†é¡¯ç¤º 0/1 Ready (å› ç‚ºæœª unseal)
- å¦‚æœ vault-1/vault-2 æŒçºŒ Pendingï¼Œæª¢æŸ¥æ˜¯å¦é‡åˆ° Anti-Affinity å•é¡Œï¼ˆåƒè¦‹[å•é¡Œ #5](#å•é¡Œ-5-vault-pod-anti-affinity-èˆ‡å–®-worker-node)ï¼‰
- é…ç½®å·²ä¿®æ­£ç‚º `preferredDuringScheduling`ï¼Œå…è¨±å–® worker node ç’°å¢ƒé‹è¡Œ

#### 5.2 åˆå§‹åŒ– Vault

```bash
# åœ¨ç¬¬ä¸€å€‹ Vault Pod ä¸ŠåŸ·è¡Œåˆå§‹åŒ–
kubectl exec -n vault vault-0 -c vault -- vault operator init \
  -key-shares=5 \
  -key-threshold=3 \
  -format=json > vault-keys.json

# é¡¯ç¤ºåˆå§‹åŒ–é‡‘é‘°
cat vault-keys.json | jq
```

**é‡è¦**: å®‰å…¨ä¿å­˜ `vault-keys.json`ï¼ŒåŒ…å«ï¼š
- `unseal_keys_b64`: 5 å€‹ Unseal Keys
- `root_token`: Root Token

#### 5.3 è§£å°æ‰€æœ‰ Vault å¯¦ä¾‹

```bash
# æå– Unseal Keys
UNSEAL_KEY_1=$(cat vault-keys.json | jq -r '.unseal_keys_b64[0]')
UNSEAL_KEY_2=$(cat vault-keys.json | jq -r '.unseal_keys_b64[1]')
UNSEAL_KEY_3=$(cat vault-keys.json | jq -r '.unseal_keys_b64[2]')

# è§£å° vault-0
kubectl exec -n vault vault-0 -c vault -- vault operator unseal $UNSEAL_KEY_1
kubectl exec -n vault vault-0 -c vault -- vault operator unseal $UNSEAL_KEY_2
kubectl exec -n vault vault-0 -c vault -- vault operator unseal $UNSEAL_KEY_3

# é©—è­‰ç‹€æ…‹
kubectl exec -n vault vault-0 -- vault status

# é æœŸè¼¸å‡º:
# Sealed: false  âœ…
# Initialized: true âœ…
```

# è§£å° vault-1 (æœƒè‡ªå‹•åŠ å…¥ Raft cluster)
kubectl exec -n vault vault-1 -- vault operator unseal $UNSEAL_KEY_1
kubectl exec -n vault vault-1 -- vault operator unseal $UNSEAL_KEY_2
kubectl exec -n vault vault-1 -- vault operator unseal $UNSEAL_KEY_3

# è§£å° vault-2 (æœƒè‡ªå‹•åŠ å…¥ Raft cluster)
kubectl exec -n vault vault-2 -- vault operator unseal $UNSEAL_KEY_1
kubectl exec -n vault vault-2 -- vault operator unseal $UNSEAL_KEY_2
kubectl exec -n vault vault-2 -- vault operator unseal $UNSEAL_KEY_3
```

**æ³¨æ„**:
- vault-1 å’Œ vault-2 åœ¨ unseal å¾Œæœƒè‡ªå‹•åŠ å…¥ vault-0 çš„ Raft cluster
- ç¬¬ä¸‰æ¬¡ unseal å‘½ä»¤å¾Œå¯èƒ½ä»é¡¯ç¤º `Sealed: true`ï¼Œä½†æ—¥èªŒæœƒé¡¯ç¤º "vault is unsealed"
- é€™æ˜¯æ­£å¸¸è¡Œç‚ºï¼ŒVault æ­£åœ¨åŠ å…¥ Raft cluster ä¸¦åŒæ­¥ç‹€æ…‹
- ç¨ç­‰ç‰‡åˆ»å¾Œæª¢æŸ¥ pod ç‹€æ…‹ï¼Œæ‡‰è©²æœƒè®Šæˆ 1/1 Ready

#### 5.4 é©—è­‰ Vault ç‹€æ…‹

```bash
# æª¢æŸ¥æ‰€æœ‰ Vault pods ç‹€æ…‹
kubectl get pods -n vault -l app.kubernetes.io/name=vault,component=server

# æª¢æŸ¥æ‰€æœ‰ Vault å¯¦ä¾‹
kubectl exec -n vault vault-0 -- vault status
kubectl exec -n vault vault-1 -- vault status
kubectl exec -n vault vault-2 -- vault status
```

**é æœŸçµæœ**:
- æ‰€æœ‰ pods é¡¯ç¤º `1/1 Running`
- vault-0: `Sealed: false`, `HA Mode: active`
- vault-1: `Sealed: false`, `HA Mode: standby`
- vault-2: `Sealed: false`, `HA Mode: standby`
- æ‰€æœ‰å¯¦ä¾‹éƒ½åœ¨åŒä¸€å€‹ Raft cluster ä¸­ (ç›¸åŒ `Cluster ID`)

**å¦‚æœ vault pods åœ¨ unseal å¾Œä»ç„¶ 0/1**:
```bash
# æª¢æŸ¥æ—¥èªŒ
kubectl logs vault-1 -n vault --tail=50
# æ‡‰è©²çœ‹åˆ° "vault is unsealed" å’Œ "entering standby mode"

# å¼·åˆ¶åˆªé™¤ä¸¦é‡å»º pods (æœƒä¿ç•™ PVC è³‡æ–™)
kubectl delete pod vault-0 vault-1 vault-2 -n vault

# ç­‰å¾… pods é‡æ–°å‰µå»ºå¾Œå†æ¬¡ unseal
# (é‡å•Ÿå¾Œ Vault æœƒé‡æ–°é€²å…¥ sealed ç‹€æ…‹)
```

---

### Phase 6: æ‡‰ç”¨éƒ¨ç½²

**ç›®æ¨™**: åŒæ­¥è§€æ¸¬æ€§å †ç–Šã€èº«ä»½èªè­‰èˆ‡æ‡‰ç”¨æœå‹™

#### 6.0 å‰ç½®æª¢æŸ¥

ç¢ºèªæ‡‰ç”¨å±¤ ApplicationSet å·²å•Ÿç”¨ï¼š

```bash
# æª¢æŸ¥ apps-appset ApplicationSet æ˜¯å¦å­˜åœ¨
kubectl get applicationset apps-appset -n argocd

# æª¢æŸ¥æ‡‰ç”¨ Applications æ˜¯å¦å·²ç”Ÿæˆ
kubectl get applications -n argocd | grep -E "postgresql|keycloak|prometheus|grafana"
```

**é æœŸè¼¸å‡º**: æ‡‰è©²çœ‹åˆ°ä»¥ä¸‹ Applicationsï¼ˆç‹€æ…‹å¯èƒ½ç‚º Unknown æˆ– OutOfSyncï¼‰:
- `postgresql` - PostgreSQL HA è³‡æ–™åº«
- `keycloak` - èº«ä»½èªè­‰èˆ‡ SSO
- `prometheus` - Prometheus + Alertmanager + Node Exporter
- `loki` - æ—¥èªŒèšåˆ
- `tempo` - åˆ†æ•£å¼è¿½è¹¤
- `mimir` - é•·æœŸæŒ‡æ¨™å„²å­˜
- `grafana` - ç›£æ§å¯è¦–åŒ–
- `alertmanager` - å‘Šè­¦ç®¡ç†
- `node-exporter` - ç¯€é»æŒ‡æ¨™æ”¶é›†
- `pgbouncer-hpa` - PostgreSQL é€£æ¥æ± 

**å¦‚æœæ²’æœ‰çœ‹åˆ°é€™äº› Applications**:
```bash
# åˆ·æ–° root application
kubectl patch application root -n argocd \
  -p='{"metadata":{"annotations":{"argocd.argoproj.io/refresh":"hard"}}}' --type=merge

# ç­‰å¾… 30 ç§’å¾Œå†æ¬¡æª¢æŸ¥
sleep 30 && kubectl get applications -n argocd
```

---

#### 6.1 æ‡‰ç”¨éƒ¨ç½²é †åºèªªæ˜

**é‡è¦**: æ‡‰ç”¨ä¹‹é–“æœ‰ä¾è³´é—œä¿‚ï¼Œå¿…é ˆæŒ‰ä»¥ä¸‹é †åºéƒ¨ç½²ï¼š

```
éšæ®µ 1: åŸºç¤æœå‹™
  â””â”€ postgresql (è³‡æ–™åº«) â† è¢« keycloak å’Œ grafana ä¾è³´

éšæ®µ 2: èº«ä»½èªè­‰
  â””â”€ keycloak (SSO/OAuth2) â† ä¾è³´ postgresqlï¼Œç‚º grafana æä¾› OAuth2

éšæ®µ 3: è§€æ¸¬æ€§åŸºç¤è¨­æ–½
  â”œâ”€ prometheus (æŒ‡æ¨™æ”¶é›†)
  â”œâ”€ loki (æ—¥èªŒèšåˆ)
  â”œâ”€ tempo (åˆ†æ•£å¼è¿½è¹¤)
  â””â”€ mimir (é•·æœŸæŒ‡æ¨™å„²å­˜)

éšæ®µ 4: å¯è¦–åŒ–
  â””â”€ grafana (ç›£æ§å„€è¡¨æ¿) â† ä¾è³´ postgresql (å­˜å„²), keycloak (OAuth2), prometheus/loki/tempo/mimir (è³‡æ–™æº)

éšæ®µ 5: è¼”åŠ©æœå‹™
  â”œâ”€ alertmanager (å‘Šè­¦ç®¡ç†)
  â”œâ”€ node-exporter (ç¯€é»æŒ‡æ¨™)
  â””â”€ pgbouncer-hpa (PostgreSQL é€£æ¥æ± )
```

---

#### 6.2 éšæ®µ 1: éƒ¨ç½² PostgreSQL (è³‡æ–™åº«)

**å„ªå…ˆç´š**: ğŸ”´ æœ€é«˜ï¼ˆè¢« keycloak å’Œ grafana ä¾è³´ï¼‰

```bash
# é¸é … 1: é€šé ArgoCD UI
# 1. è¨ªå• https://argocd.detectviz.internal
# 2. æ‰¾åˆ° "postgresql" Application
# 3. é»æ“Š "SYNC" æŒ‰éˆ•
# 4. ç­‰å¾…åŒæ­¥å®Œæˆ

# é¸é … 2: é€šé kubectl
kubectl patch application postgresql -n argocd \
  -p='{"operation":{"sync":{"prune":true}}}' --type=merge

# ç­‰å¾…éƒ¨ç½²å®Œæˆ
kubectl wait --for=condition=Ready pod -l app.kubernetes.io/name=postgresql-ha -n postgresql --timeout=300s

# é©—è­‰ PostgreSQL éƒ¨ç½²
kubectl get pods -n postgresql
kubectl get svc -n postgresql
kubectl get pvc -n postgresql
```

**é æœŸçµæœ**:
```
NAME                          READY   STATUS    RESTARTS   AGE
postgresql-ha-pgpool-0        1/1     Running   0          2m
postgresql-ha-postgresql-0    1/1     Running   0          2m
postgresql-ha-postgresql-1    1/1     Running   0          1m
```

**æ•…éšœæ’é™¤**:
- å¦‚æœ pods ä¸€ç›´ Pending: æª¢æŸ¥ PVC æ˜¯å¦ç¶å®šï¼ˆ`kubectl get pvc -n postgresql`ï¼‰
- å¦‚æœ PVC ä¸€ç›´ Pending: æª¢æŸ¥ TopoLVM æ˜¯å¦æ­£å¸¸é‹è¡Œï¼ˆåƒè¦‹ Phase 4.7ï¼‰

---

#### 6.3 éšæ®µ 2: éƒ¨ç½² Keycloak (èº«ä»½èªè­‰)

**å„ªå…ˆç´š**: ğŸŸ  é«˜ï¼ˆä¾è³´ postgresqlï¼Œç‚º grafana æä¾› OAuth2ï¼‰

```bash
# åŒæ­¥ keycloak
kubectl patch application keycloak -n argocd \
  -p='{"operation":{"sync":{"prune":true}}}' --type=merge

# ç­‰å¾…éƒ¨ç½²å®Œæˆ
kubectl wait --for=condition=Ready pod -l app.kubernetes.io/name=keycloak -n keycloak --timeout=300s

# é©—è­‰ Keycloak éƒ¨ç½²
kubectl get pods -n keycloak
kubectl get svc -n keycloak
kubectl get ingress -n keycloak
```

**é æœŸçµæœ**:
```
NAME          READY   STATUS    RESTARTS   AGE
keycloak-0    1/1     Running   0          2m
```

**è¨ªå• Keycloak**:
```bash
# ç²å– admin å¯†ç¢¼ï¼ˆå¦‚æœé…ç½®äº† secretï¼‰
kubectl get secret keycloak -n keycloak -o jsonpath='{.data.admin-password}' | base64 -d

# è¨ªå• UI
# URL: https://keycloak.detectviz.internal
# Username: admin
# Password: (ä¸Šé¢ç²å–çš„å¯†ç¢¼)
```

**å¾ŒçºŒé…ç½®** (å¯é¸ï¼Œè¦–éœ€æ±‚è€Œå®š):
- å‰µå»º Realm: `detectviz`
- é…ç½® OAuth2 Client: `grafana`
- è¨­ç½®ç”¨æˆ¶å’Œè§’è‰²

---

#### 6.4 éšæ®µ 3: éƒ¨ç½²è§€æ¸¬æ€§åŸºç¤è¨­æ–½

**å„ªå…ˆç´š**: ğŸŸ¡ ä¸­

```bash
# ä¸¦è¡ŒåŒæ­¥è§€æ¸¬æ€§çµ„ä»¶ï¼ˆç„¡ç›¸äº’ä¾è³´ï¼‰
kubectl patch application prometheus -n argocd \
  -p='{"operation":{"sync":{"prune":true}}}' --type=merge &

kubectl patch application loki -n argocd \
  -p='{"operation":{"sync":{"prune":true}}}' --type=merge &

kubectl patch application tempo -n argocd \
  -p='{"operation":{"sync":{"prune":true}}}' --type=merge &

kubectl patch application mimir -n argocd \
  -p='{"operation":{"sync":{"prune":true}}}' --type=merge &

wait  # ç­‰å¾…æ‰€æœ‰èƒŒæ™¯ä»»å‹™å®Œæˆ

# é©—è­‰éƒ¨ç½²
kubectl get pods -n prometheus
kubectl get pods -n loki
kubectl get pods -n tempo
kubectl get pods -n mimir
```

**é æœŸçµæœ** (å„å‘½åç©ºé–“):
```
# Prometheus namespace
prometheus-kube-prometheus-operator-*        1/1     Running
prometheus-kube-state-metrics-*              1/1     Running
prometheus-prometheus-node-exporter-*        1/1     Running (æ¯å€‹ç¯€é»ä¸€å€‹)
alertmanager-*                               1/1     Running
prometheus-*                                 1/1     Running

# Loki namespace
loki-*                                       1/1     Running

# Tempo namespace
tempo-*                                      1/1     Running

# Mimir namespace
mimir-*                                      å¤šå€‹ pods (åˆ†æ•£å¼æ¶æ§‹)
```

---

#### 6.5 éšæ®µ 4: éƒ¨ç½² Grafana (å¯è¦–åŒ–)

**å„ªå…ˆç´š**: ğŸŸ¢ ä½ï¼ˆä¾è³´æ‰€æœ‰å‰é¢çš„æœå‹™ï¼‰

**å…ˆæ±ºæ¢ä»¶ç¢ºèª**:
```bash
# ç¢ºèª PostgreSQL æ­£åœ¨é‹è¡Œ
kubectl get pods -n postgresql -l app.kubernetes.io/name=postgresql-ha

# ç¢ºèª Keycloak æ­£åœ¨é‹è¡Œ
kubectl get pods -n keycloak -l app.kubernetes.io/name=keycloak

# ç¢ºèªè³‡æ–™æºæ­£åœ¨é‹è¡Œ
kubectl get pods -n prometheus -l app.kubernetes.io/name=prometheus
kubectl get pods -n loki -l app.kubernetes.io/name=loki
kubectl get pods -n tempo -l app.kubernetes.io/name=tempo
kubectl get pods -n mimir -l app.kubernetes.io/name=mimir
```

**éƒ¨ç½² Grafana**:
```bash
# åŒæ­¥ grafana
kubectl patch application grafana -n argocd \
  -p='{"operation":{"sync":{"prune":true}}}' --type=merge

# ç­‰å¾…éƒ¨ç½²å®Œæˆ
kubectl wait --for=condition=Ready pod -l app.kubernetes.io/name=grafana -n grafana --timeout=300s

# é©—è­‰ Grafana éƒ¨ç½²
kubectl get pods -n grafana
kubectl get svc -n grafana
kubectl get ingress -n grafana
```

**è¨ªå• Grafana**:
```bash
# ç²å– admin å¯†ç¢¼
kubectl get secret grafana -n grafana -o jsonpath='{.data.admin-password}' | base64 -d

# è¨ªå• UI
# URL: https://grafana.detectviz.internal
# Username: admin
# Password: (ä¸Šé¢ç²å–çš„å¯†ç¢¼)
```

**Grafana é›†æˆé…ç½®** (values.yaml æ‡‰å·²é…ç½®):
- âœ… **è³‡æ–™åº«**: PostgreSQL (ç”¨æ–¼å­˜å„² dashboards, users, sessions)
- âœ… **OAuth2**: Keycloak (SSO ç™»å…¥)
- âœ… **è³‡æ–™æº**:
  - Prometheus (æŒ‡æ¨™æŸ¥è©¢)
  - Loki (æ—¥èªŒæŸ¥è©¢)
  - Tempo (è¿½è¹¤æŸ¥è©¢)
  - Mimir (é•·æœŸæŒ‡æ¨™æŸ¥è©¢)

---

#### 6.6 éšæ®µ 5: éƒ¨ç½²è¼”åŠ©æœå‹™ (å¯é¸)

```bash
# Alertmanager (å¦‚æœä¸æ˜¯ prometheus çš„ä¸€éƒ¨åˆ†)
kubectl patch application alertmanager -n argocd \
  -p='{"operation":{"sync":{"prune":true}}}' --type=merge

# Node Exporter (å¦‚æœä¸æ˜¯ prometheus çš„ä¸€éƒ¨åˆ†)
kubectl patch application node-exporter -n argocd \
  -p='{"operation":{"sync":{"prune":true}}}' --type=merge

# PgBouncer (PostgreSQL é€£æ¥æ± )
kubectl patch application pgbouncer-hpa -n argocd \
  -p='{"operation":{"sync":{"prune":true}}}' --type=merge
```

---

#### 6.7 æœ€çµ‚é©—è­‰

```bash
# æª¢æŸ¥æ‰€æœ‰æ‡‰ç”¨ç‹€æ…‹
kubectl get applications -n argocd

# æª¢æŸ¥æ‰€æœ‰ pods
kubectl get pods -A | grep -E "postgresql|keycloak|prometheus|loki|tempo|mimir|grafana"

# æª¢æŸ¥æ‰€æœ‰æœå‹™
kubectl get svc -A | grep -E "postgresql|keycloak|prometheus|loki|tempo|mimir|grafana"

# æª¢æŸ¥æ‰€æœ‰ Ingress
kubectl get ingress -A
```

**é æœŸçµæœ**: æ‰€æœ‰ Applications æ‡‰è©²ç‚º `Synced, Healthy`

**æœå‹™è¨ªå• URLs**:
- ArgoCD: https://argocd.detectviz.internal
- Keycloak: https://keycloak.detectviz.internal
- Grafana: https://grafana.detectviz.internal
- Prometheus: https://prometheus.detectviz.internal
- Alertmanager: https://alertmanager.detectviz.internal

---

#### 6.8 å¸¸è¦‹å•é¡Œè™•ç†

**å•é¡Œ 1: Applications é¡¯ç¤º Unknown æˆ– OutOfSync**

```bash
# åˆ·æ–°ç‰¹å®š application
kubectl patch application <app-name> -n argocd \
  -p='{"metadata":{"annotations":{"argocd.argoproj.io/refresh":"hard"}}}' --type=merge

# å¼·åˆ¶åŒæ­¥
kubectl patch application <app-name> -n argocd \
  -p='{"operation":{"sync":{"prune":true,"force":true}}}' --type=merge
```

**å•é¡Œ 2: Helm chart ä¸‹è¼‰å¤±æ•—**

ç¢ºèª ArgoCD å·²å•Ÿç”¨ Helm æ”¯æŒï¼š
```bash
kubectl get configmap argocd-cm -n argocd -o yaml | grep "kustomize.buildOptions"
# æ‡‰è©²çœ‹åˆ°: kustomize.buildOptions: "--enable-helm"
```

**å•é¡Œ 3: PVC ç„¡æ³•ç¶å®š**

æª¢æŸ¥ TopoLVM å’Œ StorageClassï¼š
```bash
kubectl get csistoragecapacity -A
kubectl get storageclass topolvm-provisioner
kubectl get pods -n topolvm-system
```

**å•é¡Œ 4: Grafana ç„¡æ³•é€£æ¥ PostgreSQL**

æª¢æŸ¥è³‡æ–™åº«æœå‹™å’Œå¯†ç¢¼ï¼š
```bash
kubectl get svc -n postgresql
kubectl get secret -n grafana | grep postgres
kubectl logs -n grafana -l app.kubernetes.io/name=grafana --tail=50
```

---

### Phase 7: æœ€çµ‚é©—è­‰

#### 7.1 é›†ç¾¤å¥åº·æª¢æŸ¥

```bash
# æª¢æŸ¥æ‰€æœ‰ç¯€é»
kubectl get nodes -o wide

# æª¢æŸ¥æ‰€æœ‰ Pods
kubectl get pods -A -o wide

# æª¢æŸ¥å¤±æ•—çš„ Pods
kubectl get pods -A --field-selector=status.phase!=Running,status.phase!=Succeeded

# æª¢æŸ¥äº‹ä»¶
kubectl get events -A --sort-by='.lastTimestamp' | tail -20
```

#### 7.2 ç¶²è·¯é©—è­‰

```bash
# é©—è­‰é›™ç¶²è·¯é…ç½®
./scripts/validate-dual-network.sh

# æª¢æŸ¥ MetalLB IP æ± 
kubectl get ipaddresspool -n metallb-system

# æª¢æŸ¥ Ingress
kubectl get ingress -A
```

#### 7.3 DNS é©—è­‰

```bash
# å¾ VM æ¸¬è©¦ DNS
ssh ubuntu@192.168.0.11 'nslookup argocd.detectviz.internal 192.168.0.2'
ssh ubuntu@192.168.0.11 'nslookup master-1.cluster.internal 192.168.0.2'

# å¾æœ¬æ©Ÿæ¸¬è©¦ (å¦‚æœå·²é…ç½® /etc/hosts)
curl -k https://argocd.detectviz.internal
curl -k https://grafana.detectviz.internal
```

#### 7.4 å­˜å–æœå‹™ UI

| æœå‹™ | URL | ç”¨é€” |
|------|-----|------|
| ArgoCD | https://argocd.detectviz.internal | GitOps ç®¡ç† |
| Grafana | https://grafana.detectviz.internal | ç›£æ§å„€è¡¨æ¿ |
| Prometheus | https://prometheus.detectviz.internal | æŒ‡æ¨™æŸ¥è©¢ |
| Loki | https://loki.detectviz.internal | æ—¥èªŒæŸ¥è©¢ |
| Tempo | https://tempo.detectviz.internal | è¿½è¹¤æŸ¥è©¢ |
| PgAdmin | https://pgadmin.detectviz.internal | è³‡æ–™åº«ç®¡ç† |

#### 7.5 æ•ˆèƒ½é©—è­‰

```bash
# æª¢æŸ¥è³‡æºä½¿ç”¨æƒ…æ³
kubectl top nodes
kubectl top pods -A

# æª¢æŸ¥å„²å­˜
kubectl get pvc -A
kubectl get pv

# æª¢æŸ¥ç¶²è·¯ç­–ç•¥
kubectl get networkpolicies -A
```

---

## æ•…éšœæ’é™¤

### å¸¸è¦‹å•é¡Œ

#### 1. Terraform éƒ¨ç½²å¤±æ•—

**å•é¡Œ**: VM å‰µå»ºå¤±æ•—æˆ–ç¶²è·¯é…ç½®éŒ¯èª¤

**è§£æ±ºæ–¹æ¡ˆ**:

```bash
# æª¢æŸ¥ Proxmox æ©‹æ¥å™¨
ssh root@192.168.0.2 'ip link show vmbr0'
ssh root@192.168.0.2 'ip link show vmbr1'

# æ¸…ç†å¤±æ•—çš„ VM
cd terraform/
./cleanup-failed-vms.sh

# é‡æ–°éƒ¨ç½²
terraform apply -auto-approve
```

#### 2. ç¶²è·¯é€£é€šæ€§å•é¡Œ

**å•é¡Œ**: VM ä¹‹é–“ç„¡æ³•é€šè¨Šæˆ– DNS ç„¡æ³•è§£æ

**è§£æ±ºæ–¹æ¡ˆ**:

```bash
# æª¢æŸ¥ VM ç¶²è·¯ä»‹é¢
ssh ubuntu@192.168.0.11 'ip addr show'

# æª¢æŸ¥è·¯ç”±
ssh ubuntu@192.168.0.11 'ip route'

# æª¢æŸ¥ DNS
ssh ubuntu@192.168.0.11 'cat /etc/resolv.conf'
ssh ubuntu@192.168.0.11 'nslookup master-1.detectviz.internal'

# é‡æ–°åŸ·è¡Œç¶²è·¯é…ç½®
ansible-playbook -i ansible/inventory.ini ansible/deploy-cluster.yml --tags network
```

#### 3. sysctl åƒæ•¸æœªç”Ÿæ•ˆ

**å•é¡Œ**: rp_filter æˆ– ip_forward æœªæ­£ç¢ºè¨­å®š

**è§£æ±ºæ–¹æ¡ˆ**:

```bash
# åœ¨ Proxmox æª¢æŸ¥
ssh root@192.168.0.2 'sysctl net.ipv4.conf.all.rp_filter'
ssh root@192.168.0.2 'sysctl net.ipv4.ip_forward'

# åœ¨ VM æª¢æŸ¥
ssh ubuntu@192.168.0.11 'sudo sysctl net.ipv4.conf.all.rp_filter'
ssh ubuntu@192.168.0.11 'sudo sysctl net.ipv4.ip_forward'

# å¦‚æœä¸æ­£ç¢ºï¼Œé‡æ–°æ‡‰ç”¨
ssh ubuntu@192.168.0.11 'sudo sysctl --system'
```

#### 4. Kubernetes ç¯€é»æœªå°±ç·’

**å•é¡Œ**: ç¯€é»é¡¯ç¤º NotReady ç‹€æ…‹

**è§£æ±ºæ–¹æ¡ˆ**:

```bash
# æª¢æŸ¥ç¯€é»ç‹€æ…‹
kubectl get nodes -o wide
kubectl describe node <node-name>

# æª¢æŸ¥ kubelet æ—¥èªŒ
ssh ubuntu@<node-ip> 'sudo journalctl -u kubelet -n 100 --no-pager'

# æª¢æŸ¥ CNI ç‹€æ…‹
kubectl get pods -n kube-system -l k8s-app=kube-proxy
kubectl get pods -n kube-system -l k8s-app=calico-node
```

#### 5. ArgoCD æ‡‰ç”¨åŒæ­¥å¤±æ•—

**å•é¡Œ**: æ‡‰ç”¨é¡¯ç¤º OutOfSync æˆ– Degraded

**è§£æ±ºæ–¹æ¡ˆ**:

```bash
# æª¢æŸ¥æ‡‰ç”¨ç‹€æ…‹
argocd app get <app-name>

# æŸ¥çœ‹è©³ç´°éŒ¯èª¤
kubectl describe application <app-name> -n argocd

# æ‰‹å‹•åŒæ­¥
argocd app sync <app-name> --force

# é‡ç½®æ‡‰ç”¨
argocd app delete <app-name>
argocd app create <app-name> ...
```

#### 6. ApplicationSet è·¯å¾‘éŒ¯èª¤ï¼ˆé›ç”Ÿè›‹å•é¡Œ #1ï¼‰

**ç—‡ç‹€**:
```
ComparisonError: Failed to load target state: failed to generate manifest
apps/infrastructure/cert-manager/overlays: app path does not exist
```

**æ ¹æœ¬åŸå› **: ApplicationSet ç”Ÿæˆçš„æ‡‰ç”¨è·¯å¾‘ç¼ºå°‘ `argocd/` å‰ç¶´

**è¨ºæ–·**:
```bash
# æª¢æŸ¥ Application çš„å¯¦éš›è·¯å¾‘
kubectl get application infra-cert-manager -n argocd -o jsonpath='{.spec.source.path}'
# éŒ¯èª¤è¼¸å‡º: apps/infrastructure/cert-manager/overlays
# æ­£ç¢ºè¼¸å‡º: argocd/apps/infrastructure/cert-manager/overlays

# æª¢æŸ¥ ApplicationSet é…ç½®
kubectl get applicationset detectviz-gitops -n argocd -o yaml | grep -A 2 "path:"
```

**è§£æ±ºæ–¹æ¡ˆ**:

1. ä¿®æ­£ `argocd/appsets/appset.yaml`:
```yaml
elements:
  - appName: cert-manager
    path: argocd/apps/infrastructure/cert-manager/overlays  # æ·»åŠ  argocd/ å‰ç¶´
```

2. æäº¤ä¸¦æ¨é€ä¿®æ”¹
3. åˆ·æ–° root application:
```bash
kubectl patch application root -n argocd \
  -p='{"metadata":{"annotations":{"argocd.argoproj.io/refresh":"hard"}}}' --type=merge
```

**é é˜²æªæ–½**: æ‰€æœ‰ ApplicationSet ä¸­çš„è·¯å¾‘éƒ½æ‡‰åŒ…å« `argocd/` å‰ç¶´

---

#### 7. AppProject æ¬Šé™ä¸è¶³ï¼ˆé›ç”Ÿè›‹å•é¡Œ #2ï¼‰

**ç—‡ç‹€**:
```
resource :Namespace is not permitted in project platform-bootstrap
resource :IngressClass is not permitted in project platform-bootstrap
```

**æ ¹æœ¬åŸå› **: AppProject `platform-bootstrap` çš„ `clusterResourceWhitelist` ç¼ºå°‘å¿…è¦è³‡æº

**è¨ºæ–·**:
```bash
# æª¢æŸ¥ Application éŒ¯èª¤
kubectl get application infra-cert-manager -n argocd -o yaml | grep -A 10 "conditions:"

# æª¢æŸ¥ AppProject ç™½åå–®
kubectl get appproject platform-bootstrap -n argocd -o yaml | grep -A 20 "clusterResourceWhitelist"
```

**è§£æ±ºæ–¹æ¡ˆ**:

ä¿®æ­£ `argocd/bootstrap/argocd-projects.yaml`:
```yaml
clusterResourceWhitelist:
  - group: ""
    kind: Namespace       # æ·»åŠ  Namespace
  - group: networking.k8s.io
    kind: IngressClass    # æ·»åŠ  IngressClass
  - group: apiextensions.k8s.io
    kind: CustomResourceDefinition
  # ... å…¶ä»–è³‡æº
```

**é é˜²æªæ–½**: åœ¨æ·»åŠ æ–°åŸºç¤è¨­æ–½çµ„ä»¶å‰ï¼Œç¢ºèª AppProject å·²åŒ…å«æ‰€éœ€çš„è³‡æºé¡å‹

---

#### 8. cluster-bootstrap CRD ä¾è³´å•é¡Œï¼ˆé›ç”Ÿè›‹å•é¡Œ #3ï¼‰

**ç—‡ç‹€**:
```
cluster-bootstrap: OutOfSync, Progressing
no matches for kind "Certificate" in version "cert-manager.io/v1"
ensure CRDs are installed first
```

**æ ¹æœ¬åŸå› **: cluster-bootstrap Phase 2 è³‡æºï¼ˆCertificates, Ingressï¼‰ä¾è³´å°šæœªéƒ¨ç½²çš„ CRDs

**é€™æ˜¯æ­£å¸¸ä¸”é æœŸçš„è¡Œç‚ºï¼**

**è§£æ±ºæ–¹æ¡ˆ**ï¼ˆå·²å…§å»ºæ–¼éƒ¨ç½²æµç¨‹ï¼‰:

1. **Phase 1** (Sync Wave: -10): Namespaces â†’ ç«‹å³æˆåŠŸ âœ…
2. **Phase 2** (Sync Wave: 10): Certificates, Ingress â†’ å¤±æ•—ï¼ˆCRDs ä¸å­˜åœ¨ï¼‰âš ï¸
3. **æ‰‹å‹•åŒæ­¥åŸºç¤è¨­æ–½**: cert-manager, ingress-nginx â†’ CRDs å®‰è£ âœ…
4. **Phase 2 è‡ªå‹•é‡è©¦**: Certificates, Ingress â†’ æˆåŠŸ âœ…

**é©—è­‰**:
```bash
# åŸºç¤è¨­æ–½åŒæ­¥å‰
kubectl get application cluster-bootstrap -n argocd
# é æœŸ: OutOfSync, Progressing âš ï¸ é€™æ˜¯æ­£å¸¸çš„!

# åŸºç¤è¨­æ–½åŒæ­¥å¾Œ
kubectl get application cluster-bootstrap -n argocd
# é æœŸ: Synced, Healthy âœ…
```

**é—œéµè¨­å®š**ï¼ˆå·²é…ç½®ï¼‰:
```yaml
# argocd/bootstrap/manifests/*.yaml
metadata:
  annotations:
    argocd.argoproj.io/sync-options: SkipDryRunOnMissingResource=true
    argocd.argoproj.io/sync-wave: "10"  # å»¶å¾Œéƒ¨ç½²
```

---

#### 9. TopoLVM Pod ç„¡æ³•èª¿åº¦ï¼ˆé›ç”Ÿè›‹å•é¡Œ #4ï¼‰

**ç—‡ç‹€**:
```
Vault pods: Pending
Events: 0/1 nodes are available: 1 Insufficient topolvm.io/capacity
å¯¦éš›ç¯€é»å®¹é‡: 240GB
éœ€æ±‚: 45GB
```

**æ ¹æœ¬åŸå› **: ä½¿ç”¨ Scheduler Extender æ¨¡å¼ä½† kube-scheduler æœªé…ç½® extender endpoint

**è¨ºæ–·**:
```bash
# æª¢æŸ¥ Pod è³‡æºè«‹æ±‚
kubectl get pod vault-0 -n vault -o yaml | grep "topolvm.io/capacity"
# éŒ¯èª¤: topolvm.io/capacity: "1"  (åƒ… 1 byte!)

# æª¢æŸ¥ç¯€é» annotation
kubectl get node app-worker -o jsonpath='{.metadata.annotations}' | grep topolvm
# æ­£ç¢º: capacity.topolvm.io/00default: "257693843456"  (240GB)

# æª¢æŸ¥ CSIStorageCapacity è³‡æº
kubectl get csistoragecapacity -A
# èˆŠæ¨¡å¼: No resources found  âŒ
# æ–°æ¨¡å¼: æ‡‰è©²é¡¯ç¤º topolvm å®¹é‡ âœ…
```

**è§£æ±ºæ–¹æ¡ˆ**ï¼ˆå·²å¯¦æ–½ï¼‰:

æ”¹ç”¨ **Storage Capacity Tracking** æ¨¡å¼ï¼ˆ`argocd/apps/infrastructure/topolvm/overlays/values.yaml`ï¼‰:

```yaml
scheduler:
  enabled: false  # ç¦ç”¨ scheduler extender

controller:
  storageCapacityTracking:
    enabled: true  # å•Ÿç”¨ Storage Capacity Tracking

webhook:
  podMutatingWebhook:
    enabled: false  # ä¸éœ€è¦ pod webhook
```

**é‡æ–°éƒ¨ç½²å¾Œé©—è­‰**:
```bash
# 1. æª¢æŸ¥ CSIStorageCapacity è³‡æº
kubectl get csistoragecapacity -A
# é æœŸ: æ‡‰è©²çœ‹åˆ° topolvm-provisioner çš„å®¹é‡è³‡æº

# 2. æª¢æŸ¥ topolvm-scheduler DaemonSet ä¸æ‡‰å­˜åœ¨
kubectl get daemonset -n kube-system topolvm-scheduler
# é æœŸ: Error from server (NotFound)  âœ…

# 3. åˆªé™¤èˆŠ Vault pods è®“å®ƒå€‘é‡å»ºï¼ˆæ¸…é™¤èˆŠ webhook mutationsï¼‰
kubectl delete pod -n vault --all

# 4. æª¢æŸ¥æ–° pods æ˜¯å¦æˆåŠŸèª¿åº¦
kubectl get pods -n vault -o wide
# é æœŸ: Running ç‹€æ…‹ï¼Œèª¿åº¦åˆ° app-worker
```

**ç‚ºä»€éº¼é€™å€‹æ–¹æ¡ˆæ›´å¥½**:
- âœ… Kubernetes åŸç”ŸåŠŸèƒ½ï¼ˆ1.21+ GAï¼‰
- âœ… ç„¡éœ€ä¿®æ”¹ kube-scheduler é…ç½®
- âœ… è‡ªå‹•å®¹é‡è¿½è¹¤å’Œæ›´æ–°
- âœ… æ›´ç°¡å–®ã€æ›´å¯é çš„èª¿åº¦æ©Ÿåˆ¶

---

#### 11. Ingress-Nginx LoadBalancer ç„¡æ³•åˆ†é… IP

**ç—‡ç‹€**:
- ingress-nginx-controller æœå‹™ EXTERNAL-IP é¡¯ç¤º `<pending>`
- ç„¡æ³•è¨ªå• https://argocd.detectviz.internal
- curl é€£æ¥è¢«æ‹’çµ• (Connection refused)
- æ‰€æœ‰é€šé Ingress æš´éœ²çš„æœå‹™éƒ½ç„¡æ³•è¨ªå•

**æ ¹æœ¬åŸå› **:

1. **MetalLB IP æ± é…ç½®ä¸å®Œæ•´**: IP æ± ç¼ºå°‘ `192.168.0.10`
   ```yaml
   # éŒ¯èª¤é…ç½®
   spec:
     addresses:
       - 192.168.0.200-192.168.0.220  # ç¼ºå°‘ .10
   ```

2. **ä½¿ç”¨ deprecated `spec.loadBalancerIP` æ¬„ä½**: èˆ‡ MetalLB è¨»è§£ `metallb.universe.tf/loadBalancerIPs` è¡çª
   ```
   MetalLB éŒ¯èª¤: service can not have both metallb.universe.tf/loadBalancerIPs and svc.Spec.LoadBalancerIP
   ```

3. **`externalTrafficPolicy: Local` å°è‡´å¥åº·æª¢æŸ¥å¤±æ•—**: MetalLB speaker å®£å‘Š IP å¾Œç«‹å³æ’¤å›
   ```
   MetalLB æ—¥èªŒ:
   "service has IP, announcing" ips=["192.168.0.10"]
   "withdrawing service announcement" reason="noIPAllocated"
   ```

**è¨ºæ–·æ­¥é©Ÿ**:

```bash
# 1. æª¢æŸ¥æœå‹™ç‹€æ…‹
kubectl get svc ingress-nginx-controller -n ingress-nginx
# ç—‡ç‹€: EXTERNAL-IP = <pending>

# 2. æª¢æŸ¥ MetalLB IP æ± 
kubectl get ipaddresspool -n metallb-system default-pool -o yaml
# æª¢æŸ¥æ˜¯å¦åŒ…å« 192.168.0.10

# 3. æª¢æŸ¥ MetalLB speaker æ—¥èªŒ
kubectl logs -n metallb-system -l component=speaker --tail=50
# å°‹æ‰¾ "withdrawing service announcement" æˆ–å…¶ä»–éŒ¯èª¤

# 4. æª¢æŸ¥æœå‹™é…ç½®è¡çª
kubectl get svc ingress-nginx-controller -n ingress-nginx -o yaml | grep -E "loadBalancerIP|loadBalancerIPs"
# æª¢æŸ¥æ˜¯å¦åŒæ™‚ä½¿ç”¨äº† spec.loadBalancerIP å’Œè¨»è§£
```

**è§£æ±ºæ–¹æ¡ˆ**:

1. **æ·»åŠ  `192.168.0.10/32` åˆ° MetalLB IPAddressPool**:

   ç·¨è¼¯ `argocd/apps/infrastructure/metallb/overlays/ipaddresspool.yaml`:
   ```yaml
   apiVersion: metallb.io/v1beta1
   kind: IPAddressPool
   metadata:
     name: default-pool
     namespace: metallb-system
   spec:
     addresses:
       - 192.168.0.10/32  # âœ… æ·»åŠ  Ingress Controller VIP
       - 192.168.0.200-192.168.0.220  # å‹•æ…‹ IP æ± 
   ```

2. **ç§»é™¤ deprecated `spec.loadBalancerIP` æ¬„ä½**:

   ç·¨è¼¯ `argocd/apps/infrastructure/ingress-nginx/overlays/ingress-nginx-service.yaml`:
   ```yaml
   apiVersion: v1
   kind: Service
   metadata:
     name: ingress-nginx-controller
     namespace: ingress-nginx
   spec:
     type: LoadBalancer
     # âŒ ç§»é™¤é€™ä¸€è¡Œ:
     # loadBalancerIP: 192.168.0.10
   ```

3. **ä½¿ç”¨ `externalTrafficPolicy: Cluster` æ¨¡å¼**:

   ç·¨è¼¯ `argocd/apps/infrastructure/ingress-nginx/overlays/ingress-nginx-service.yaml`:
   ```yaml
   apiVersion: v1
   kind: Service
   metadata:
     name: ingress-nginx-controller
     namespace: ingress-nginx
   spec:
     type: LoadBalancer
     externalTrafficPolicy: Cluster  # âœ… æ”¹ç‚º Cluster æ¨¡å¼
     ports:
       - name: http
         port: 80
         protocol: TCP
         targetPort: http
       - name: https
         port: 443
         protocol: TCP
         targetPort: https
     selector:
       app.kubernetes.io/name: ingress-nginx
       app.kubernetes.io/instance: ingress-nginx
       app.kubernetes.io/component: controller
   ```

4. **ç¢ºä¿ Helm values.yaml é…ç½®ä¸€è‡´**:

   ç·¨è¼¯ `argocd/apps/infrastructure/ingress-nginx/overlays/values.yaml`:
   ```yaml
   ingress-nginx:
     controller:
       service:
         enabled: true
         type: LoadBalancer
         externalTrafficPolicy: Cluster  # èˆ‡ patch ä¸€è‡´
   ```

5. **é€šé Strategic Merge Patch æ­£ç¢ºé…ç½®æœå‹™**:

   ç¢ºä¿ `argocd/apps/infrastructure/ingress-nginx/overlays/kustomization.yaml` åŒ…å«:
   ```yaml
   patchesStrategicMerge:
     - ingress-nginx-service.yaml  # æ˜ç¢ºçš„æœå‹™é…ç½®
   ```

**é©—è­‰ä¿®å¾©**:

```bash
# 1. åŒæ­¥ MetalLB é…ç½®
kubectl apply -k argocd/apps/infrastructure/metallb/overlays/

# 2. åŒæ­¥ Ingress-Nginx é…ç½®
kubectl apply -k argocd/apps/infrastructure/ingress-nginx/overlays/

# 3. ç­‰å¾…æœå‹™é‡æ–°å‰µå»º
kubectl rollout status deployment ingress-nginx-controller -n ingress-nginx

# 4. æª¢æŸ¥ EXTERNAL-IP
kubectl get svc ingress-nginx-controller -n ingress-nginx
# é æœŸ: EXTERNAL-IP = 192.168.0.10

# 5. æª¢æŸ¥ Ingress è³‡æº
kubectl get ingress -n argocd argocd-server
# é æœŸ: ADDRESS = 192.168.0.10

# 6. æ¸¬è©¦ HTTPS é€£æ¥
curl -k -I https://argocd.detectviz.internal
# é æœŸ: HTTP/2 307 (ArgoCD é‡å®šå‘)

# 7. æª¢æŸ¥ MetalLB speaker æ—¥èªŒ
kubectl logs -n metallb-system -l component=speaker --tail=20
# é æœŸ: "service has IP, announcing" ä¸”æ²’æœ‰ "withdrawing" è¨Šæ¯
```

**externalTrafficPolicy æ¨¡å¼å°æ¯”**:

| ç‰¹æ€§ | Local | Cluster |
|-----|-------|---------|
| ä¿ç•™æº IP | âœ… æ˜¯ | âŒ å¦ (SNAT) |
| è² è¼‰å‡è¡¡ | åƒ…æœ¬åœ° Pod | å…¨é›†ç¾¤ Pod |
| å¥åº·æª¢æŸ¥ | éœ€è¦ healthCheckNodePort | ä¸éœ€è¦ |
| MetalLB ç›¸å®¹æ€§ | âš ï¸ éœ€è¦å¥åº·æª¢æŸ¥é€šé | âœ… ç„¡é¡å¤–è¦æ±‚ |
| é©ç”¨å ´æ™¯ | ç”Ÿç”¢ç’°å¢ƒ (éœ€è¦æº IP) | æ¸¬è©¦/é–‹ç™¼ç’°å¢ƒ |

**ç‚ºä½•é¸æ“‡ Cluster æ¨¡å¼**:
- âœ… é¿å… MetalLB L2 æ¨¡å¼ä¸‹çš„å¥åº·æª¢æŸ¥å•é¡Œ
- âœ… æ›´ç°¡å–®çš„é…ç½®,ç„¡éœ€é¡å¤–çš„å¥åº·æª¢æŸ¥è¨­ç½®
- âš ï¸ ç¼ºé»: ç„¡æ³•ä¿ç•™å®¢æˆ¶ç«¯æº IP (å°æ–¼ Ingress é€šå¸¸ä¸é‡è¦)

**ç›¸é—œæ–‡ä»¶**:
- `ingress-nginx-loadbalancer-fix.md` - å®Œæ•´ä¿®å¾©éç¨‹å’ŒæŠ€è¡“æ´å¯Ÿ
- Commits:
  - `bbab4f2` - "fix: Add 192.168.0.10 to MetalLB IP pool"
  - `16bb52d` - "fix: Remove deprecated loadBalancerIP field"
  - `8bafac7` - "fix: Configure externalTrafficPolicy=Cluster"
  - `959332d` - "fix: Re-add ingress-nginx-service.yaml with correct config"

**é æœŸçµæœ**:
- âœ… EXTERNAL-IP: 192.168.0.10 æˆåŠŸåˆ†é…
- âœ… HTTPS æ­£å¸¸è¨ªå•: https://argocd.detectviz.internal
- âœ… MetalLB ç©©å®šé‹è¡Œ,ç„¡ IP æ’¤å›å•é¡Œ
- âœ… æ‰€æœ‰ Ingress è³‡æºæ­£å¸¸å·¥ä½œ

---

#### 10. MTU å•é¡Œ

**å•é¡Œ**: è¨­å®š MTU 9000 å¾Œç„¡æ³•é€£ç·šæˆ–å°åŒ…ä¸Ÿå¤±

**åŸå› **: ç¶²å¡ã€äº¤æ›æ©Ÿæˆ–ç·šæä¸æ”¯æ´å·¨å‹å¹€ï¼ˆJumbo Framesï¼‰

**è¨ºæ–·æ­¥é©Ÿ**:

```bash
# 1. æ¸¬è©¦æ¨™æº– MTU (1472 bytes payload + 28 bytes header = 1500 bytes)
ping -c 3 -M do -s 1472 192.168.0.11
# é æœŸ: æˆåŠŸ

# 2. æ¸¬è©¦å·¨å‹å¹€ MTU (8972 bytes payload + 28 bytes header = 9000 bytes)
ping -c 3 -M do -s 8972 192.168.0.11
# å¦‚æœå¤±æ•—ï¼Œè¡¨ç¤ºè·¯å¾‘ä¸­æœ‰è¨­å‚™ä¸æ”¯æ´ MTU 9000

# 3. æª¢æŸ¥ Proxmox ç¶²å¡æœ€å¤§æ”¯æ´
ip link show enp4s0
# æŸ¥çœ‹ "mtu" æ¬„ä½çš„æœ€å¤§å€¼

# 4. æª¢æŸ¥æ‰€æœ‰ VM çš„ MTU
ansible all -i ansible/inventory.ini -m shell -a "ip link show | grep mtu"
```

**è§£æ±ºæ–¹æ¡ˆ**:

```bash
# æ–¹æ¡ˆ A: æ”¹å› MTU 1500ï¼ˆå»ºè­°ï¼‰
# 1. ä¿®æ”¹ terraform/terraform.tfvars
#    proxmox_mtu = 1500
# 2. ä¿®æ”¹ Proxmox /etc/network/interfaces
#    mtu 1500
# 3. é‡å•Ÿç¶²è·¯
systemctl restart networking

# æ–¹æ¡ˆ B: é€æ­¥æå‡ MTU æ‰¾å‡ºæœ€å¤§æ”¯æ´å€¼
# æ¸¬è©¦ä¸åŒçš„ MTU å€¼
ping -c 3 -M do -s 1972 192.168.0.11  # 2000 MTU
ping -c 3 -M do -s 3972 192.168.0.11  # 4000 MTU
ping -c 3 -M do -s 7972 192.168.0.11  # 8000 MTU
# æ‰¾å‡ºå¯ç”¨çš„æœ€å¤§å€¼å¾Œè¨­å®š

# é‡æ–°é…ç½® VM ç¶²è·¯
ansible-playbook -i ansible/inventory.ini ansible/deploy-cluster.yml --tags network
```

**æ³¨æ„äº‹é …**:
- MTU 9000 éœ€è¦**æ•´æ¢è·¯å¾‘**ï¼ˆProxmox ç¶²å¡â†’äº¤æ›æ©Ÿâ†’VM ç¶²å¡ï¼‰éƒ½æ”¯æ´
- ä¸€èˆ¬å®¶ç”¨ç¶²å¡å’Œäº¤æ›æ©Ÿåªæ”¯æ´ MTU 1500
- ä¼æ¥­ç´š NIC å’Œäº¤æ›æ©Ÿé€šå¸¸æ”¯æ´ MTU 9000
- å°æ–¼å°å‹ Kubernetes é›†ç¾¤ï¼ŒMTU 1500 å·²è¶³å¤ ï¼Œä¸æœƒæœ‰æ˜é¡¯æ•ˆèƒ½å·®ç•°

---

### æ¸…ç†èˆ‡é‡æ–°éƒ¨ç½²

#### æ¸…ç†å¤±æ•—çš„ VM éƒ¨ç½²

å¦‚æœ Terraform éƒ¨ç½²ä¸­é€”å¤±æ•—ï¼š

```bash
cd terraform/
./cleanup-failed-vms.sh
```

æ­¤è…³æœ¬å°‡ï¼š
- æª¢æŸ¥ä¸¦æ¸…ç† Terraform ç‹€æ…‹
- æä¾›æ‰‹å‹•æ¸…ç† Proxmox VM çš„è©³ç´°æŒ‡ä»¤

#### å®Œå…¨é‡æ–°éƒ¨ç½²

å¦‚æœéœ€è¦å¾é ­é–‹å§‹æ•´å€‹é›†ç¾¤éƒ¨ç½²ï¼š

```bash
cd terraform/
./cleanup-and-redeploy.sh
```

æ­¤è…³æœ¬å°‡ï¼š
- è‡ªå‹•éŠ·æ¯€æ‰€æœ‰ç¾æœ‰è³‡æº
- é‡æ–°åˆå§‹åŒ–ä¸¦éƒ¨ç½²æ–°åŸºç¤è¨­æ–½
- é©ç”¨æ–¼é–‹ç™¼æ¸¬è©¦æˆ–é‡å¤§é…ç½®è®Šæ›´

#### æ‰‹å‹•æ¸…ç†æ­¥é©Ÿ

å¦‚æœè‡ªå‹•åŒ–è…³æœ¬ç„¡æ³•ä½¿ç”¨ï¼š

1. **éŠ·æ¯€ Terraform è³‡æº**:
   ```bash
   cd terraform/
   terraform destroy -auto-approve
   ```

2. **æ‰‹å‹•åˆªé™¤ Proxmox VM**:
   ```bash
   # åœ¨ Proxmox ä¸ŠåŸ·è¡Œ
   qm stop 111 && qm destroy 111
   qm stop 112 && qm destroy 112
   qm stop 113 && qm destroy 113
   qm stop 114 && qm destroy 114
   ```

3. **æ¸…ç† Terraform ç‹€æ…‹**:
   ```bash
   rm -rf .terraform/
   rm terraform.tfstate*
   ```

4. **æ¸…ç† Ansible ç”Ÿæˆçš„æ–‡ä»¶**:
   ```bash
   rm -rf ansible/kubeconfig/
   rm ansible/inventory.ini
   ```

5. **é‡ç½® Proxmox ç¶²è·¯**ï¼ˆå¦‚éœ€è¦ï¼‰:
   ```bash
   # åœ¨ Proxmox ä¸ŠåŸ·è¡Œ
   systemctl restart networking
   ```

---

### è¨ºæ–·å·¥å…·

#### ç¶²è·¯è¨ºæ–·

```bash
# åŸ·è¡Œå®Œæ•´ç¶²è·¯é©—è­‰
./scripts/validate-dual-network.sh

# åˆ†æ®µé©—è­‰
./scripts/validate-dual-network.sh --proxmox
./scripts/validate-dual-network.sh --vms
./scripts/validate-dual-network.sh --dns
./scripts/validate-dual-network.sh --connectivity
```

#### é›†ç¾¤è¨ºæ–·

```bash
# æª¢æŸ¥é›†ç¾¤å¥åº·ç‹€æ…‹
./scripts/health-check.sh

# æª¢æŸ¥ DNS
./scripts/test-cluster-dns.sh

# è¨ºæ–·ç‰¹å®šç¯€é»ç¶²è·¯å•é¡Œ
./scripts/diagnose-vm1-network.sh
```

---

### åƒè€ƒæ–‡æª”

- **ç¶²è·¯è¦åŠƒ**: `docs/infrastructure/00-planning/configuration-network.md`
- **åŸŸåé…ç½®**: `docs/infrastructure/00-planning/configuration-domain.md`
- **å„²å­˜è¦åŠƒ**: `docs/infrastructure/00-planning/configuration-storage.md`
- **Proxmox é…ç½®**: `docs/infrastructure/02-proxmox/`
- **Terraform æ–‡æª”**: `terraform/README.md`
- **Ansible æ–‡æª”**: `ansible/README.md`

---

> [!IMPORTANT]
> **ç”Ÿç”¢ç’°å¢ƒæ³¨æ„äº‹é …**:
> - å®šæœŸå‚™ä»½ Vault é‡‘é‘° (`vault-keys.json`)
> - å®šæœŸå‚™ä»½ kubeconfig (`ansible/kubeconfig/admin.conf`)
> - å®šæœŸå‚™ä»½ Terraform ç‹€æ…‹ (`terraform/terraform.tfstate`)
> - ç›£æ§ç£ç¢Ÿç©ºé–“å’Œç¶²è·¯æµé‡
> - å®šæœŸæ›´æ–° Kubernetes ç‰ˆæœ¬å’Œæ‡‰ç”¨çµ„ä»¶

> [!TIP]
> **æ•ˆèƒ½å„ªåŒ–å»ºè­°**:
> - **MTU è¨­å®š**: é è¨­ä½¿ç”¨ 1500ï¼Œåƒ…åœ¨ç¢ºèªç¡¬é«”æ”¯æ´æ™‚æ‰å•Ÿç”¨ MTU 9000ï¼ˆå·¨å‹å¹€ï¼‰
> - **rp_filter**: ä½¿ç”¨ `rp_filter = 2` (å¯¬é¬†æ¨¡å¼) ä»¥æ”¯æ´éå°ç¨±è·¯ç”±
> - **sysctl åƒæ•¸**: å®šæœŸæª¢æŸ¥åƒæ•¸æ˜¯å¦æ­£ç¢ºæ‡‰ç”¨
> - **é›™ç¶²è·¯æ¶æ§‹**: ä½¿ç”¨å…§éƒ¨é›†ç¾¤ç¶²è·¯ (vmbr1) é€²è¡Œ Kubernetes ç¯€é»é–“é€šè¨Šä»¥æå‡æ•ˆèƒ½
> - **MTU æ¸¬è©¦**: ä½¿ç”¨ `ping -M do -s <size>` æ¸¬è©¦è·¯å¾‘æœ€å¤§ MTU
